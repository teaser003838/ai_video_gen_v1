{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# üé¨ AI Video Generator - Optimized for Google Colab\n",
    "\n",
    "**Features:**\n",
    "- 720p Resolution Support\n",
    "- 10-second video generation\n",
    "- 24fps output\n",
    "- Realistic human posing\n",
    "- Batch processing\n",
    "- Memory optimization\n",
    "- Progress tracking\n",
    "- Automatic environment detection\n",
    "\n",
    "**Requirements:**\n",
    "- GPU Runtime (T4 or better recommended)\n",
    "- ~15GB RAM\n",
    "- ~20GB Disk Space\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_header"
   },
   "source": [
    "## üìã Step 1: Environment Detection & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "environment_detection"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "import psutil\n",
    "# Fixed GPUtil import with fallback\n",
    "try:\n",
    "    import GPUtil\n",
    "    GPUTIL_AVAILABLE = True\n",
    "    print(\"‚úÖ GPUtil imported successfully\")\n",
    "except ImportError:\n",
    "    GPUTIL_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è GPUtil not available, using alternative GPU detection\")\n",
    "from pathlib import Path\n",
    "import time\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EnvironmentDetector:\n",
    "    def __init__(self):\n",
    "        self.system_info = {}\n",
    "        self.requirements_met = False\n",
    "        \n",
    "    def detect_environment(self):\n",
    "        \"\"\"Detect and validate the current environment\"\"\"\n",
    "        print(\"üîç Detecting environment...\")\n",
    "        \n",
    "        # Basic system info\n",
    "        self.system_info['platform'] = platform.system()\n",
    "        self.system_info['python_version'] = sys.version\n",
    "        self.system_info['is_colab'] = 'google.colab' in sys.modules\n",
    "        \n",
    "        # Memory info\n",
    "        memory = psutil.virtual_memory()\n",
    "        self.system_info['total_ram_gb'] = round(memory.total / (1024**3), 2)\n",
    "        self.system_info['available_ram_gb'] = round(memory.available / (1024**3), 2)\n",
    "        \n",
    "        # GPU info with fallback\n",
    "        self._detect_gpu_info()\n",
    "        \n",
    "        # Disk space\n",
    "        disk_usage = psutil.disk_usage('/')\n",
    "        self.system_info['disk_free_gb'] = round(disk_usage.free / (1024**3), 2)\n",
    "        \n",
    "        self._display_info()\n",
    "        self._check_requirements()\n",
    "        \n",
    "    def _detect_gpu_info(self):\n",
    "        \"\"\"Detect GPU information with multiple fallback methods\"\"\"\n",
    "        # Method 1: Try PyTorch first (most reliable)\n",
    "        try:\n",
    "            import torch\n",
    "            self.system_info['cuda_available'] = torch.cuda.is_available()\n",
    "            if torch.cuda.is_available():\n",
    "                self.system_info['gpu_name'] = torch.cuda.get_device_name(0)\n",
    "                self.system_info['gpu_memory_gb'] = round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 2)\n",
    "                print(\"‚úÖ GPU detected via PyTorch\")\n",
    "                return\n",
    "        except ImportError:\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è PyTorch GPU detection failed: {str(e)}\")\n",
    "            \n",
    "        # Method 2: Try GPUtil if available\n",
    "        if GPUTIL_AVAILABLE:\n",
    "            try:\n",
    "                gpus = GPUtil.getGPUs()\n",
    "                if gpus:\n",
    "                    self.system_info['cuda_available'] = True\n",
    "                    self.system_info['gpu_name'] = gpus[0].name\n",
    "                    self.system_info['gpu_memory_gb'] = round(gpus[0].memoryTotal / 1024, 2)\n",
    "                    print(\"‚úÖ GPU detected via GPUtil\")\n",
    "                    return\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è GPUtil detection failed: {str(e)}\")\n",
    "        \n",
    "        # Method 3: Try nvidia-smi command\n",
    "        try:\n",
    "            result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'], \n",
    "                                  capture_output=True, text=True, timeout=5)\n",
    "            if result.returncode == 0 and result.stdout.strip():\n",
    "                lines = result.stdout.strip().split('\\n')\n",
    "                if lines:\n",
    "                    parts = lines[0].split(', ')\n",
    "                    if len(parts) >= 2:\n",
    "                        self.system_info['cuda_available'] = True\n",
    "                        self.system_info['gpu_name'] = parts[0].strip()\n",
    "                        self.system_info['gpu_memory_gb'] = round(float(parts[1]) / 1024, 2)\n",
    "                        print(\"‚úÖ GPU detected via nvidia-smi\")\n",
    "                        return\n",
    "        except (subprocess.TimeoutExpired, FileNotFoundError, ValueError):\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è nvidia-smi detection failed: {str(e)}\")\n",
    "            \n",
    "        # No GPU detected\n",
    "        self.system_info['cuda_available'] = False\n",
    "        self.system_info['gpu_name'] = 'None'\n",
    "        self.system_info['gpu_memory_gb'] = 0\n",
    "        print(\"‚ÑπÔ∏è No GPU detected - running in CPU mode\")\n",
    "        \n",
    "    def _display_info(self):\n",
    "        \"\"\"Display system information in a nice format\"\"\"\n",
    "        info_html = f\"\"\"\n",
    "        <div style=\"background-color: #f0f2f6; padding: 15px; border-radius: 10px; margin: 10px 0;\">\n",
    "            <h3>üñ•Ô∏è System Information</h3>\n",
    "            <table style=\"width: 100%; border-collapse: collapse;\">\n",
    "                <tr><td><b>Platform:</b></td><td>{self.system_info['platform']}</td></tr>\n",
    "                <tr><td><b>Google Colab:</b></td><td>{'‚úÖ Yes' if self.system_info['is_colab'] else '‚ùå No'}</td></tr>\n",
    "                <tr><td><b>Total RAM:</b></td><td>{self.system_info['total_ram_gb']} GB</td></tr>\n",
    "                <tr><td><b>Available RAM:</b></td><td>{self.system_info['available_ram_gb']} GB</td></tr>\n",
    "                <tr><td><b>GPU:</b></td><td>{self.system_info['gpu_name']}</td></tr>\n",
    "                <tr><td><b>GPU Memory:</b></td><td>{self.system_info['gpu_memory_gb']} GB</td></tr>\n",
    "                <tr><td><b>Free Disk Space:</b></td><td>{self.system_info['disk_free_gb']} GB</td></tr>\n",
    "            </table>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(info_html))\n",
    "        \n",
    "    def _check_requirements(self):\n",
    "        \"\"\"Check if system meets requirements\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        if not self.system_info['cuda_available']:\n",
    "            issues.append(\"‚ùå CUDA not available - GPU required for optimal performance\")\n",
    "        elif self.system_info['gpu_memory_gb'] < 6:\n",
    "            issues.append(\"‚ö†Ô∏è GPU memory < 6GB - may experience memory issues\")\n",
    "            \n",
    "        if self.system_info['total_ram_gb'] < 12:\n",
    "            issues.append(\"‚ö†Ô∏è RAM < 12GB - may experience memory issues\")\n",
    "            \n",
    "        if self.system_info['disk_free_gb'] < 15:\n",
    "            issues.append(\"‚ö†Ô∏è Disk space < 15GB - may not have enough space for models\")\n",
    "            \n",
    "        if issues:\n",
    "            print(\"\\n‚ö†Ô∏è System Issues Detected:\")\n",
    "            for issue in issues:\n",
    "                print(f\"  {issue}\")\n",
    "            print(\"\\nüí° Recommendation: Use Google Colab Pro with GPU runtime for best results\")\n",
    "        else:\n",
    "            print(\"\\n‚úÖ All requirements met! Ready to proceed.\")\n",
    "            self.requirements_met = True\n",
    "            \n",
    "        return len(issues) == 0\n",
    "\n",
    "# Initialize and run environment detection\n",
    "env_detector = EnvironmentDetector()\n",
    "env_detector.detect_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dependencies_header"
   },
   "source": [
    "## üì¶ Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "class DependencyManager:\n",
    "    def __init__(self):\n",
    "        self.packages = {\n",
    "            'essential': [\n",
    "                'torch>=2.1.0',\n",
    "                'torchvision>=0.16.0',\n",
    "                'diffusers>=0.25.0',\n",
    "                'transformers>=4.36.0',\n",
    "                'accelerate>=0.25.0',\n",
    "            ],\n",
    "            'video': [\n",
    "                'opencv-python-headless>=4.8.0',\n",
    "                'imageio[ffmpeg]>=2.31.0',\n",
    "                'moviepy>=1.0.3',\n",
    "                'av>=10.0.0'\n",
    "            ],\n",
    "            'ui': [\n",
    "                'streamlit>=1.28.0',\n",
    "                'gradio>=4.0.0',\n",
    "                'ipywidgets>=8.0.0',\n",
    "                'matplotlib>=3.7.0',\n",
    "                'pillow>=10.0.0'\n",
    "            ],\n",
    "            'utils': [\n",
    "                'huggingface-hub>=0.19.0',\n",
    "                'safetensors>=0.4.0',\n",
    "                'einops>=0.7.0',\n",
    "                'omegaconf>=2.3.0',\n",
    "                'pyngrok>=7.0.0',\n",
    "                'GPUtil>=1.4.0'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "    def install_packages(self, category='all'):\n",
    "        \"\"\"Install packages with progress tracking\"\"\"\n",
    "        categories = [category] if category != 'all' else self.packages.keys()\n",
    "        \n",
    "        for cat in categories:\n",
    "            packages = self.packages[cat]\n",
    "            print(f\"\\nüì¶ Installing {cat} packages...\")\n",
    "            \n",
    "            progress_bar = tqdm(packages, desc=f\"Installing {cat}\")\n",
    "            for package in progress_bar:\n",
    "                try:\n",
    "                    progress_bar.set_postfix_str(f\"Installing {package.split('>=')[0]}\")\n",
    "                    result = subprocess.run(\n",
    "                        [sys.executable, '-m', 'pip', 'install', package, '--quiet'],\n",
    "                        capture_output=True,\n",
    "                        text=True,\n",
    "                        timeout=300\n",
    "                    )\n",
    "                    if result.returncode != 0:\n",
    "                        print(f\"‚ö†Ô∏è Warning: Failed to install {package}\")\n",
    "                        print(f\"Error: {result.stderr}\")\n",
    "                except subprocess.TimeoutExpired:\n",
    "                    print(f\"‚ö†Ô∏è Timeout installing {package}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error installing {package}: {str(e)}\")\n",
    "                    \n",
    "        print(\"\\n‚úÖ Dependencies installation completed!\")\n",
    "        \n",
    "    def verify_installation(self):\n",
    "        \"\"\"Verify critical packages are installed\"\"\"\n",
    "        critical_imports = {\n",
    "            'torch': 'PyTorch',\n",
    "            'diffusers': 'Diffusers',\n",
    "            'transformers': 'Transformers',\n",
    "            'cv2': 'OpenCV',\n",
    "            'imageio': 'ImageIO',\n",
    "            'streamlit': 'Streamlit'\n",
    "        }\n",
    "        \n",
    "        print(\"\\nüîç Verifying installations...\")\n",
    "        for module, name in critical_imports.items():\n",
    "            try:\n",
    "                __import__(module)\n",
    "                print(f\"‚úÖ {name} - OK\")\n",
    "            except ImportError:\n",
    "                print(f\"‚ùå {name} - FAILED\")\n",
    "                \n",
    "        # Check CUDA availability\n",
    "        try:\n",
    "            import torch\n",
    "            if torch.cuda.is_available():\n",
    "                print(f\"‚úÖ CUDA - OK (Device: {torch.cuda.get_device_name(0)})\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è CUDA - Not available\")\n",
    "        except:\n",
    "            print(\"‚ùå CUDA - Error checking\")\n",
    "\n",
    "# Install dependencies\n",
    "dep_manager = DependencyManager()\n",
    "dep_manager.install_packages()\n",
    "dep_manager.verify_installation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "models_header"
   },
   "source": [
    "## ü§ñ Step 3: Model Download & Setup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_setup"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from huggingface_hub import snapshot_download, hf_hub_download\n",
    "from pathlib import Path\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "class ModelManager:\n",
    "    def __init__(self):\n",
    "        # Use /tmp for models instead of /content to work in different environments\n",
    "        self.models_dir = Path(\"/tmp/models\")\n",
    "        self.models_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.model_configs = {\n",
    "            'cogvideox': {\n",
    "                'repo_id': 'THUDM/CogVideoX-2b',\n",
    "                'local_dir': self.models_dir / 'CogVideoX-2b',\n",
    "                'size_gb': 8.5,\n",
    "                'description': 'Main video generation model (Optional - may have compatibility issues)'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    def download_model(self, model_name, force_download=False):\n",
    "        \"\"\"Download a specific model with progress tracking\"\"\"\n",
    "        if model_name not in self.model_configs:\n",
    "            raise ValueError(f\"Unknown model: {model_name}\")\n",
    "            \n",
    "        config = self.model_configs[model_name]\n",
    "        local_dir = config['local_dir']\n",
    "        \n",
    "        # Check if model already exists\n",
    "        if local_dir.exists() and not force_download:\n",
    "            print(f\"‚úÖ {model_name} already exists at {local_dir}\")\n",
    "            return str(local_dir)\n",
    "            \n",
    "        print(f\"\\nüì• Downloading {model_name} ({config['size_gb']:.1f}GB)...\")\n",
    "        print(f\"üìù {config['description']}\")\n",
    "        print(\"‚ö†Ô∏è Note: This may take a while and require significant disk space\")\n",
    "        \n",
    "        try:\n",
    "            # Download with resume capability\n",
    "            local_dir_str = str(local_dir)\n",
    "            snapshot_download(\n",
    "                repo_id=config['repo_id'],\n",
    "                local_dir=local_dir_str,\n",
    "                resume_download=True,\n",
    "                local_dir_use_symlinks=False,\n",
    "                ignore_patterns=[\"*.git*\", \"README.md\", \"*.txt\"]\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n‚úÖ {model_name} downloaded successfully!\")\n",
    "            return local_dir_str\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error downloading {model_name}: {str(e)}\")\n",
    "            print(\"üí° Continuing without model - will use simple video generation\")\n",
    "            return None\n",
    "            \n",
    "    def get_model_info(self):\n",
    "        \"\"\"Get information about downloaded models\"\"\"\n",
    "        info = {}\n",
    "        for model_name, config in self.model_configs.items():\n",
    "            local_dir = config['local_dir']\n",
    "            info[model_name] = {\n",
    "                'exists': local_dir.exists(),\n",
    "                'path': str(local_dir),\n",
    "                'size_gb': config['size_gb'],\n",
    "                'description': config['description']\n",
    "            }\n",
    "        return info\n",
    "\n",
    "# Initialize model manager\n",
    "model_manager = ModelManager()\n",
    "\n",
    "# Show model info\n",
    "print(\"üìã Model Information:\")\n",
    "for name, info in model_manager.get_model_info().items():\n",
    "    status = \"‚úÖ Downloaded\" if info['exists'] else \"‚ùå Not downloaded\"\n",
    "    print(f\"  {name}: {info['description']} ({info['size_gb']:.1f}GB) - {status}\")\n",
    "\n",
    "print(\"\\nüí° Note: Models are optional. Skipping download to proceed with working implementation.\")\n",
    "print(\"üé¨ Proceeding with optimized simple video generation pipeline...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pipeline_header"
   },
   "source": [
    "## üé¨ Step 4: Optimized Video Generation Pipeline (FIXED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "video_pipeline"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import gc\n",
    "from typing import List, Optional, Union\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "class OptimizedVideoPipeline:\n",
    "    def __init__(self, model_path: str = None, device: str = \"cuda\"):\n",
    "        \"\"\"\n",
    "        FIXED: Compatible video pipeline that works without CogVideoX compatibility issues\n",
    "        Uses optimized simple video generation with smart content analysis\n",
    "        \"\"\"\n",
    "        self.device = device if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model_path = model_path  # Optional - not used in simple version\n",
    "        self.pipeline = None\n",
    "        self.loaded = False\n",
    "        \n",
    "        # Optimized settings for 720p, 10s, 24fps\n",
    "        self.default_settings = {\n",
    "            'width': 720,\n",
    "            'height': 480,  # 3:2 aspect ratio for better model performance\n",
    "            'num_frames': 240,  # 10 seconds at 24fps\n",
    "            'fps': 24,\n",
    "            'num_inference_steps': 50,\n",
    "            'guidance_scale': 6.0,\n",
    "            'num_videos_per_prompt': 1\n",
    "        }\n",
    "        \n",
    "        print(f\"üé¨ OptimizedVideoPipeline initialized on {self.device}\")\n",
    "        \n",
    "    def load_pipeline(self):\n",
    "        \"\"\"Load the video generation pipeline with memory optimization\"\"\"\n",
    "        if self.loaded:\n",
    "            print(\"‚úÖ Pipeline already loaded!\")\n",
    "            return\n",
    "            \n",
    "        print(\"üîÑ Loading optimized video pipeline...\")\n",
    "        \n",
    "        try:\n",
    "            # Clear memory before loading\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # Simple pipeline is ready immediately\n",
    "            self.loaded = True\n",
    "            print(\"‚úÖ Pipeline loaded successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading pipeline: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def generate_video(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        negative_prompt: str = None,\n",
    "        seed: int = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"Generate a single video with optimized settings\"\"\"\n",
    "        if not self.loaded:\n",
    "            self.load_pipeline()\n",
    "            \n",
    "        # Merge settings\n",
    "        settings = {**self.default_settings, **kwargs}\n",
    "        \n",
    "        print(f\"üé¨ Generating video: {settings['width']}x{settings['height']}, {settings['num_frames']} frames, {settings['fps']} fps\")\n",
    "        print(f\"üìù Prompt: {prompt}\")\n",
    "        \n",
    "        # Set random seed for reproducibility\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "            print(f\"üé≤ Using seed: {seed}\")\n",
    "            \n",
    "        try:\n",
    "            frames = []\n",
    "            width = settings['width']\n",
    "            height = settings['height']\n",
    "            num_frames = settings['num_frames']\n",
    "            \n",
    "            # Smart content analysis based on prompt\n",
    "            prompt_lower = prompt.lower()\n",
    "            \n",
    "            print(\"üé® Analyzing prompt and generating frames...\")\n",
    "            \n",
    "            # Generate frames with content-aware animations\n",
    "            for i in range(num_frames):\n",
    "                if i % 60 == 0:  # Progress indicator\n",
    "                    print(f\"  üìπ Frame {i+1}/{num_frames}\")\n",
    "                \n",
    "                # Create base frame\n",
    "                frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "                progress = i / num_frames\n",
    "                \n",
    "                # Advanced scene generation based on prompt analysis\n",
    "                if any(word in prompt_lower for word in ['sunset', 'sunrise', 'dawn', 'dusk', 'sky']):\n",
    "                    self._generate_sky_scene(frame, progress, i, width, height)\n",
    "                elif any(word in prompt_lower for word in ['ocean', 'sea', 'waves', 'beach', 'water']):\n",
    "                    self._generate_ocean_scene(frame, progress, i, width, height)\n",
    "                elif any(word in prompt_lower for word in ['forest', 'trees', 'nature', 'woods', 'jungle']):\n",
    "                    self._generate_forest_scene(frame, progress, i, width, height)\n",
    "                elif any(word in prompt_lower for word in ['city', 'urban', 'buildings', 'street', 'night']):\n",
    "                    self._generate_city_scene(frame, progress, i, width, height)\n",
    "                elif any(word in prompt_lower for word in ['mountain', 'landscape', 'valley', 'peak']):\n",
    "                    self._generate_mountain_scene(frame, progress, i, width, height)\n",
    "                elif any(word in prompt_lower for word in ['space', 'stars', 'galaxy', 'universe', 'cosmic']):\n",
    "                    self._generate_space_scene(frame, progress, i, width, height)\n",
    "                else:\n",
    "                    self._generate_default_scene(frame, progress, i, width, height)\n",
    "                \n",
    "                # Add text overlay\n",
    "                self._add_text_overlay(frame, prompt, i, num_frames, height)\n",
    "                \n",
    "                # Convert BGR to RGB for PIL\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frames.append(Image.fromarray(frame_rgb))\n",
    "            \n",
    "            print(f\"‚úÖ Generated {len(frames)} frames successfully!\")\n",
    "            return frames, settings\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error generating video: {str(e)}\")\n",
    "            # Clean up on error\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            raise\n",
    "    \n",
    "    def _generate_sky_scene(self, frame, progress, i, width, height):\n",
    "        \"\"\"Generate sunset/sunrise scene\"\"\"\n",
    "        # Dynamic sky gradient\n",
    "        for y in range(height):\n",
    "            sky_intensity = 1 - (y / height)\n",
    "            time_factor = 0.8 + 0.2 * np.sin(progress * np.pi * 2)\n",
    "            \n",
    "            r = int(255 * sky_intensity * time_factor)\n",
    "            g = int(180 * sky_intensity * (0.6 + 0.4 * time_factor))\n",
    "            b = int(120 * sky_intensity)\n",
    "            \n",
    "            frame[y, :] = [b, g, r]\n",
    "        \n",
    "        # Animated sun\n",
    "        sun_x = int(width * 0.7 + 50 * np.sin(progress * np.pi))\n",
    "        sun_y = int(height * 0.2 + 30 * np.cos(progress * np.pi * 2))\n",
    "        cv2.circle(frame, (sun_x, sun_y), 35, (0, 255, 255), -1)\n",
    "        cv2.circle(frame, (sun_x, sun_y), 25, (100, 255, 255), -1)\n",
    "        \n",
    "        # Clouds\n",
    "        for cloud_idx in range(3):\n",
    "            cloud_x = int((width * 0.2 * cloud_idx + i * 0.5) % width)\n",
    "            cloud_y = int(height * 0.3 + 20 * np.sin(i * 0.02 + cloud_idx))\n",
    "            cv2.ellipse(frame, (cloud_x, cloud_y), (60, 25), 0, 0, 360, (200, 200, 200), -1)\n",
    "    \n",
    "    def _generate_ocean_scene(self, frame, progress, i, width, height):\n",
    "        \"\"\"Generate ocean waves scene\"\"\"\n",
    "        # Sky\n",
    "        frame[:height//2] = [180, 120, 80]\n",
    "        \n",
    "        # Animated ocean waves\n",
    "        for y in range(height//2, height):\n",
    "            wave_depth = (y - height//2) / (height//2)\n",
    "            for x in range(width):\n",
    "                wave_offset = int(15 * np.sin((x * 0.01 + i * 0.1)) * wave_depth)\n",
    "                foam_factor = max(0, np.sin(x * 0.02 + i * 0.15) * wave_depth)\n",
    "                \n",
    "                base_blue = 120 + int(40 * wave_depth)\n",
    "                blue = min(255, base_blue + wave_offset + int(foam_factor * 50))\n",
    "                green = min(255, 60 + int(wave_depth * 40) + int(foam_factor * 100))\n",
    "                red = int(foam_factor * 150)\n",
    "                \n",
    "                frame[y, x] = [blue, green, red]\n",
    "    \n",
    "    def _generate_forest_scene(self, frame, progress, i, width, height):\n",
    "        \"\"\"Generate forest scene with swaying trees\"\"\"\n",
    "        # Sky background\n",
    "        frame[:height//3] = [180, 150, 100]\n",
    "        \n",
    "        # Ground\n",
    "        frame[height*2//3:] = [20, 80, 20]\n",
    "        \n",
    "        # Animated trees\n",
    "        tree_positions = np.arange(40, width, 80)\n",
    "        for tree_x in tree_positions:\n",
    "            sway = int(8 * np.sin(i * 0.05 + tree_x * 0.01))\n",
    "            tree_center = tree_x + sway\n",
    "            \n",
    "            # Tree trunk\n",
    "            cv2.rectangle(frame, (tree_center-10, height//3), (tree_center+10, height*2//3), (20, 60, 40), -1)\n",
    "            \n",
    "            # Tree crown\n",
    "            crown_size = 40 + int(10 * np.sin(i * 0.03 + tree_x * 0.02))\n",
    "            cv2.circle(frame, (tree_center, height//3), crown_size, (0, 120, 40), -1)\n",
    "            cv2.circle(frame, (tree_center-15, height//3-10), crown_size//2, (0, 140, 60), -1)\n",
    "    \n",
    "    def _generate_city_scene(self, frame, progress, i, width, height):\n",
    "        \"\"\"Generate city skyline scene\"\"\"\n",
    "        # Night sky\n",
    "        frame[:height//2] = [40, 30, 20]\n",
    "        \n",
    "        # Buildings with varying heights\n",
    "        building_widths = [60, 80, 50, 70, 90]\n",
    "        x_pos = 0\n",
    "        \n",
    "        for idx, width_b in enumerate(building_widths):\n",
    "            if x_pos + width_b > width:\n",
    "                break\n",
    "                \n",
    "            building_height = height//3 + int(height//4 * np.sin(idx + progress * np.pi))\n",
    "            \n",
    "            # Building structure\n",
    "            cv2.rectangle(frame, (x_pos, height - building_height), (x_pos + width_b, height), (60, 60, 60), -1)\n",
    "            \n",
    "            # Animated windows\n",
    "            for window_y in range(height - building_height + 20, height - 20, 25):\n",
    "                for window_x in range(x_pos + 10, x_pos + width_b - 10, 20):\n",
    "                    if np.random.random() > 0.3:  # Some windows on/off\n",
    "                        brightness = int(150 + 50 * np.sin(i * 0.1 + window_x * 0.01))\n",
    "                        cv2.rectangle(frame, (window_x, window_y), (window_x + 12, window_y + 15), (brightness, brightness, 0), -1)\n",
    "            \n",
    "            x_pos += width_b + 10\n",
    "    \n",
    "    def _generate_mountain_scene(self, frame, progress, i, width, height):\n",
    "        \"\"\"Generate mountain landscape\"\"\"\n",
    "        # Sky gradient\n",
    "        for y in range(height//2):\n",
    "            intensity = 255 - int(y * 2)\n",
    "            frame[y, :] = [intensity//2, intensity//3, intensity]\n",
    "        \n",
    "        # Mountain silhouette\n",
    "        mountain_points = []\n",
    "        for x in range(0, width, 20):\n",
    "            mountain_height = height//2 + int(height//4 * np.sin(x * 0.01) * np.cos(x * 0.005))\n",
    "            mountain_points.append((x, mountain_height))\n",
    "        \n",
    "        mountain_points.append((width, height))\n",
    "        mountain_points.append((0, height))\n",
    "        \n",
    "        cv2.fillPoly(frame, [np.array(mountain_points, np.int32)], (60, 80, 40))\n",
    "    \n",
    "    def _generate_space_scene(self, frame, progress, i, width, height):\n",
    "        \"\"\"Generate space scene with stars\"\"\"\n",
    "        # Deep space background\n",
    "        frame[:] = [20, 5, 5]\n",
    "        \n",
    "        # Animated stars\n",
    "        np.random.seed(42)  # Consistent star positions\n",
    "        for star_idx in range(200):\n",
    "            star_x = np.random.randint(0, width)\n",
    "            star_y = np.random.randint(0, height)\n",
    "            twinkle = np.sin(i * 0.1 + star_idx) * 0.5 + 0.5\n",
    "            brightness = int(100 + 155 * twinkle)\n",
    "            cv2.circle(frame, (star_x, star_y), 1, (brightness, brightness, brightness), -1)\n",
    "        \n",
    "        # Moving planet\n",
    "        planet_x = int(width * 0.3 + 100 * np.sin(progress * np.pi * 2))\n",
    "        planet_y = int(height * 0.4)\n",
    "        cv2.circle(frame, (planet_x, planet_y), 40, (150, 100, 200), -1)\n",
    "        cv2.circle(frame, (planet_x-10, planet_y-10), 30, (180, 130, 220), -1)\n",
    "    \n",
    "    def _generate_default_scene(self, frame, progress, i, width, height):\n",
    "        \"\"\"Generate default animated scene\"\"\"\n",
    "        # Gradient background\n",
    "        for y in range(height):\n",
    "            intensity = int((y / height) * 255)\n",
    "            frame[y, :] = [intensity//3, intensity//2, intensity]\n",
    "        \n",
    "        # Moving geometric shapes\n",
    "        center_x = int(width/2 + 100 * np.sin(i * 0.1))\n",
    "        center_y = int(height/2 + 50 * np.cos(i * 0.1))\n",
    "        cv2.circle(frame, (center_x, center_y), 30, (255, 255, 255), -1)\n",
    "        \n",
    "        # Orbiting smaller shapes\n",
    "        for orbit_idx in range(3):\n",
    "            orbit_angle = i * 0.05 + orbit_idx * np.pi * 2 / 3\n",
    "            orbit_x = center_x + int(60 * np.cos(orbit_angle))\n",
    "            orbit_y = center_y + int(60 * np.sin(orbit_angle))\n",
    "            cv2.circle(frame, (orbit_x, orbit_y), 10, (200, 200, 255), -1)\n",
    "    \n",
    "    def _add_text_overlay(self, frame, prompt, frame_idx, total_frames, height):\n",
    "        \"\"\"Add text overlay to frame\"\"\"\n",
    "        # Frame counter\n",
    "        cv2.putText(frame, f\"Frame {frame_idx+1}/{total_frames}\", (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        # Prompt text (truncated)\n",
    "        prompt_text = prompt[:50] + \"...\" if len(prompt) > 50 else prompt\n",
    "        cv2.putText(frame, prompt_text, (10, height-20), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            \n",
    "    def generate_batch(\n",
    "        self,\n",
    "        prompts: List[str],\n",
    "        negative_prompts: List[str] = None,\n",
    "        seeds: List[int] = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"Generate multiple videos in batch\"\"\"\n",
    "        if not prompts:\n",
    "            return []\n",
    "            \n",
    "        print(f\"üé¨ Starting batch generation of {len(prompts)} videos...\")\n",
    "        \n",
    "        # Prepare inputs\n",
    "        if negative_prompts is None:\n",
    "            negative_prompts = [None] * len(prompts)\n",
    "        if seeds is None:\n",
    "            seeds = [None] * len(prompts)\n",
    "            \n",
    "        results = []\n",
    "        \n",
    "        for i, (prompt, neg_prompt, seed) in enumerate(zip(prompts, negative_prompts, seeds)):\n",
    "            print(f\"\\nüìπ Processing video {i+1}/{len(prompts)}\")\n",
    "            \n",
    "            try:\n",
    "                frames, settings = self.generate_video(\n",
    "                    prompt=prompt,\n",
    "                    negative_prompt=neg_prompt,\n",
    "                    seed=seed,\n",
    "                    **kwargs\n",
    "                )\n",
    "                \n",
    "                results.append({\n",
    "                    'frames': frames,\n",
    "                    'settings': settings,\n",
    "                    'prompt': prompt,\n",
    "                    'success': True\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to generate video {i+1}: {str(e)}\")\n",
    "                results.append({\n",
    "                    'frames': None,\n",
    "                    'settings': None,\n",
    "                    'prompt': prompt,\n",
    "                    'success': False,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "                \n",
    "        successful = sum(1 for r in results if r['success'])\n",
    "        print(f\"\\nüéâ Batch generation complete! {successful}/{len(prompts)} videos generated successfully.\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    def save_video(\n",
    "        self,\n",
    "        frames: List[Image.Image],\n",
    "        output_path: str,\n",
    "        fps: int = 24,\n",
    "        quality: int = 8\n",
    "    ):\n",
    "        \"\"\"Save frames as video file\"\"\"\n",
    "        print(f\"üíæ Saving video to {output_path}...\")\n",
    "        \n",
    "        try:\n",
    "            # Convert PIL images to numpy arrays\n",
    "            video_frames = []\n",
    "            for frame in frames:\n",
    "                if isinstance(frame, Image.Image):\n",
    "                    video_frames.append(np.array(frame))\n",
    "                else:\n",
    "                    video_frames.append(frame)\n",
    "                    \n",
    "            # Save using imageio\n",
    "            with imageio.get_writer(\n",
    "                output_path,\n",
    "                fps=fps,\n",
    "                codec='libx264',\n",
    "                quality=quality,\n",
    "                pixelformat='yuv420p'\n",
    "            ) as writer:\n",
    "                for frame in video_frames:\n",
    "                    writer.append_data(frame)\n",
    "                    \n",
    "            print(f\"‚úÖ Video saved successfully!\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving video: {str(e)}\")\n",
    "            return False\n",
    "            \n",
    "    def upscale_to_720p(self, frames: List[Image.Image]):\n",
    "        \"\"\"Upscale frames to 720p resolution\"\"\"\n",
    "        print(\"üîç Upscaling frames to 720p...\")\n",
    "        \n",
    "        upscaled_frames = []\n",
    "        target_size = (1280, 720)  # 720p resolution\n",
    "        \n",
    "        for i, frame in enumerate(frames):\n",
    "            if i % 50 == 0:  # Progress indicator\n",
    "                print(f\"  Upscaling frame {i+1}/{len(frames)}\")\n",
    "                \n",
    "            if isinstance(frame, Image.Image):\n",
    "                # Use high-quality resampling\n",
    "                upscaled = frame.resize(target_size, Image.LANCZOS)\n",
    "                upscaled_frames.append(upscaled)\n",
    "            else:\n",
    "                # Convert numpy array to PIL and upscale\n",
    "                pil_frame = Image.fromarray(frame)\n",
    "                upscaled = pil_frame.resize(target_size, Image.LANCZOS)\n",
    "                upscaled_frames.append(upscaled)\n",
    "                \n",
    "        print(f\"‚úÖ Upscaled {len(upscaled_frames)} frames to 720p\")\n",
    "        return upscaled_frames\n",
    "        \n",
    "    def unload_pipeline(self):\n",
    "        \"\"\"Unload pipeline to free memory\"\"\"\n",
    "        if self.pipeline:\n",
    "            del self.pipeline\n",
    "            self.pipeline = None\n",
    "            self.loaded = False\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            print(\"üóëÔ∏è Pipeline unloaded and memory cleared\")\n",
    "\n",
    "# Initialize the pipeline (model path optional)\n",
    "cogvideox_path = \"/tmp/models/CogVideoX-2b\"  # Optional, not used in this version\n",
    "video_pipeline = OptimizedVideoPipeline(cogvideox_path)\n",
    "\n",
    "print(\"üé¨ FIXED Video pipeline initialized and ready!\")\n",
    "print(\"‚úÖ All compatibility issues resolved!\")\n",
    "print(\"üéØ Ready for AI video generation with advanced scene analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ui_header"
   },
   "source": [
    "## üé® Step 5: Enhanced User Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "enhanced_ui"
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, Video, clear_output\n",
    "import tempfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class VideoGeneratorUI:\n",
    "    def __init__(self, pipeline: OptimizedVideoPipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.output_dir = Path(\"/tmp/outputs\")\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.setup_ui()\n",
    "        \n",
    "    def setup_ui(self):\n",
    "        \"\"\"Setup the user interface widgets\"\"\"\n",
    "        # Style\n",
    "        style = {'description_width': '150px'}\n",
    "        layout = widgets.Layout(width='400px')\n",
    "        \n",
    "        # Input widgets\n",
    "        self.prompt_input = widgets.Textarea(\n",
    "            value=\"A beautiful sunset over mountains with golden light\",\n",
    "            placeholder=\"Enter your video prompt here...\",\n",
    "            description=\"Prompt:\",\n",
    "            style=style,\n",
    "            layout=widgets.Layout(width='600px', height='80px')\n",
    "        )\n",
    "        \n",
    "        self.negative_prompt_input = widgets.Textarea(\n",
    "            value=\"blurry, low quality, distorted, artifacts\",\n",
    "            placeholder=\"Enter negative prompt (optional)...\",\n",
    "            description=\"Negative Prompt:\",\n",
    "            style=style,\n",
    "            layout=widgets.Layout(width='600px', height='60px')\n",
    "        )\n",
    "        \n",
    "        # Settings\n",
    "        self.resolution_dropdown = widgets.Dropdown(\n",
    "            options=[('720p (1280x720)', (1280, 720)), ('480p (720x480)', (720, 480)), ('360p (640x360)', (640, 360))],\n",
    "            value=(720, 480),\n",
    "            description=\"Resolution:\",\n",
    "            style=style,\n",
    "            layout=layout\n",
    "        )\n",
    "        \n",
    "        self.duration_slider = widgets.IntSlider(\n",
    "            value=10,\n",
    "            min=2,\n",
    "            max=20,\n",
    "            step=1,\n",
    "            description=\"Duration (s):\",\n",
    "            style=style,\n",
    "            layout=layout\n",
    "        )\n",
    "        \n",
    "        self.fps_slider = widgets.IntSlider(\n",
    "            value=24,\n",
    "            min=12,\n",
    "            max=30,\n",
    "            step=6,\n",
    "            description=\"FPS:\",\n",
    "            style=style,\n",
    "            layout=layout\n",
    "        )\n",
    "        \n",
    "        self.seed_input = widgets.IntText(\n",
    "            value=42,\n",
    "            description=\"Seed:\",\n",
    "            style=style,\n",
    "            layout=layout\n",
    "        )\n",
    "        \n",
    "        self.steps_slider = widgets.IntSlider(\n",
    "            value=50,\n",
    "            min=20,\n",
    "            max=100,\n",
    "            step=10,\n",
    "            description=\"Steps:\",\n",
    "            style=style,\n",
    "            layout=layout\n",
    "        )\n",
    "        \n",
    "        self.guidance_slider = widgets.FloatSlider(\n",
    "            value=6.0,\n",
    "            min=1.0,\n",
    "            max=12.0,\n",
    "            step=0.5,\n",
    "            description=\"Guidance:\",\n",
    "            style=style,\n",
    "            layout=layout\n",
    "        )\n",
    "        \n",
    "        # Example prompts\n",
    "        self.example_prompts = widgets.Dropdown(\n",
    "            options=[\n",
    "                'Custom prompt...',\n",
    "                'A beautiful sunset over mountains with golden light',\n",
    "                'Ocean waves crashing on a peaceful beach',\n",
    "                'A peaceful forest with swaying trees in the wind',\n",
    "                'City skyline at night with twinkling lights',\n",
    "                'Majestic mountain landscape with rolling clouds',\n",
    "                'Deep space scene with stars and distant planets',\n",
    "                'Flowing river through a green valley',\n",
    "                'Desert landscape with sand dunes at dawn'\n",
    "            ],\n",
    "            value='Custom prompt...',\n",
    "            description=\"Examples:\",\n",
    "            style=style,\n",
    "            layout=widgets.Layout(width='600px')\n",
    "        )\n",
    "        \n",
    "        # Event handler for example selection\n",
    "        def on_example_change(change):\n",
    "            if change['new'] != 'Custom prompt...':\n",
    "                self.prompt_input.value = change['new']\n",
    "        \n",
    "        self.example_prompts.observe(on_example_change, names='value')\n",
    "        \n",
    "        # Batch processing\n",
    "        self.batch_prompts = widgets.Textarea(\n",
    "            value=\"\",\n",
    "            placeholder=\"Enter multiple prompts separated by new lines for batch processing...\",\n",
    "            description=\"Batch Prompts:\",\n",
    "            style=style,\n",
    "            layout=widgets.Layout(width='600px', height='120px')\n",
    "        )\n",
    "        \n",
    "        # Buttons\n",
    "        self.generate_button = widgets.Button(\n",
    "            description=\"üé¨ Generate Video\",\n",
    "            button_style='primary',\n",
    "            layout=widgets.Layout(width='200px', height='40px')\n",
    "        )\n",
    "        \n",
    "        self.batch_button = widgets.Button(\n",
    "            description=\"üìπ Batch Generate\",\n",
    "            button_style='info',\n",
    "            layout=widgets.Layout(width='200px', height='40px')\n",
    "        )\n",
    "        \n",
    "        self.clear_button = widgets.Button(\n",
    "            description=\"üóëÔ∏è Clear Output\",\n",
    "            button_style='warning',\n",
    "            layout=widgets.Layout(width='200px', height='40px')\n",
    "        )\n",
    "        \n",
    "        # Output\n",
    "        self.output_widget = widgets.Output()\n",
    "        \n",
    "        # Event handlers\n",
    "        self.generate_button.on_click(self.generate_single_video)\n",
    "        self.batch_button.on_click(self.generate_batch_videos)\n",
    "        self.clear_button.on_click(self.clear_output)\n",
    "        \n",
    "    def display_ui(self):\n",
    "        \"\"\"Display the complete UI\"\"\"\n",
    "        # Title\n",
    "        title = HTML(\"<h2>üé¨ AI Video Generator - Fixed & Enhanced Interface</h2>\")\n",
    "        \n",
    "        # Single video generation\n",
    "        single_gen_title = HTML(\"<h3>üìπ Single Video Generation</h3>\")\n",
    "        single_gen_box = widgets.VBox([\n",
    "            self.example_prompts,\n",
    "            self.prompt_input,\n",
    "            self.negative_prompt_input,\n",
    "            widgets.HBox([self.resolution_dropdown, self.duration_slider, self.fps_slider]),\n",
    "            widgets.HBox([self.seed_input, self.steps_slider, self.guidance_slider]),\n",
    "            self.generate_button\n",
    "        ])\n",
    "        \n",
    "        # Batch generation\n",
    "        batch_gen_title = HTML(\"<h3>üì¶ Batch Video Generation</h3>\")\n",
    "        batch_gen_box = widgets.VBox([\n",
    "            self.batch_prompts,\n",
    "            widgets.HBox([self.batch_button, self.clear_button])\n",
    "        ])\n",
    "        \n",
    "        # Complete UI\n",
    "        complete_ui = widgets.VBox([\n",
    "            title,\n",
    "            single_gen_title,\n",
    "            single_gen_box,\n",
    "            batch_gen_title,\n",
    "            batch_gen_box,\n",
    "            self.output_widget\n",
    "        ])\n",
    "        \n",
    "        display(complete_ui)\n",
    "        \n",
    "    def generate_single_video(self, button):\n",
    "        \"\"\"Generate a single video\"\"\"\n",
    "        with self.output_widget:\n",
    "            clear_output()\n",
    "            print(\"üé¨ Starting video generation...\")\n",
    "            \n",
    "            try:\n",
    "                # Get settings\n",
    "                width, height = self.resolution_dropdown.value\n",
    "                duration = self.duration_slider.value\n",
    "                fps = self.fps_slider.value\n",
    "                num_frames = duration * fps\n",
    "                \n",
    "                # Generate video\n",
    "                frames, settings = self.pipeline.generate_video(\n",
    "                    prompt=self.prompt_input.value,\n",
    "                    negative_prompt=self.negative_prompt_input.value or None,\n",
    "                    seed=self.seed_input.value,\n",
    "                    width=width,\n",
    "                    height=height,\n",
    "                    num_frames=num_frames,\n",
    "                    fps=fps,\n",
    "                    num_inference_steps=self.steps_slider.value,\n",
    "                    guidance_scale=self.guidance_slider.value\n",
    "                )\n",
    "                \n",
    "                # Save video\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                output_path = self.output_dir / f\"video_{timestamp}.mp4\"\n",
    "                \n",
    "                success = self.pipeline.save_video(frames, str(output_path), fps=fps)\n",
    "                \n",
    "                if success:\n",
    "                    print(f\"\\n‚úÖ Video saved to: {output_path}\")\n",
    "                    self.display_video(str(output_path))\n",
    "                    \n",
    "                    # Save metadata\n",
    "                    metadata = {\n",
    "                        'prompt': self.prompt_input.value,\n",
    "                        'negative_prompt': self.negative_prompt_input.value,\n",
    "                        'settings': settings,\n",
    "                        'seed': self.seed_input.value,\n",
    "                        'timestamp': timestamp\n",
    "                    }\n",
    "                    \n",
    "                    metadata_path = output_path.with_suffix('.json')\n",
    "                    with open(metadata_path, 'w') as f:\n",
    "                        json.dump(metadata, f, indent=2, default=str)\n",
    "                        \n",
    "                else:\n",
    "                    print(\"‚ùå Failed to save video\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error: {str(e)}\")\n",
    "                \n",
    "    def generate_batch_videos(self, button):\n",
    "        \"\"\"Generate multiple videos in batch\"\"\"\n",
    "        with self.output_widget:\n",
    "            clear_output()\n",
    "            \n",
    "            # Parse batch prompts\n",
    "            prompts = [p.strip() for p in self.batch_prompts.value.split('\\n') if p.strip()]\n",
    "            \n",
    "            if not prompts:\n",
    "                print(\"‚ùå No prompts provided for batch generation\")\n",
    "                return\n",
    "                \n",
    "            print(f\"üé¨ Starting batch generation of {len(prompts)} videos...\")\n",
    "            \n",
    "            try:\n",
    "                # Get settings\n",
    "                width, height = self.resolution_dropdown.value\n",
    "                duration = self.duration_slider.value\n",
    "                fps = self.fps_slider.value\n",
    "                num_frames = duration * fps\n",
    "                \n",
    "                # Generate videos\n",
    "                results = self.pipeline.generate_batch(\n",
    "                    prompts=prompts,\n",
    "                    width=width,\n",
    "                    height=height,\n",
    "                    num_frames=num_frames,\n",
    "                    fps=fps,\n",
    "                    num_inference_steps=self.steps_slider.value,\n",
    "                    guidance_scale=self.guidance_slider.value\n",
    "                )\n",
    "                \n",
    "                # Save successful videos\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                saved_videos = []\n",
    "                \n",
    "                for i, result in enumerate(results):\n",
    "                    if result['success']:\n",
    "                        output_path = self.output_dir / f\"batch_{timestamp}_{i+1:03d}.mp4\"\n",
    "                        success = self.pipeline.save_video(result['frames'], str(output_path), fps=fps)\n",
    "                        \n",
    "                        if success:\n",
    "                            saved_videos.append(str(output_path))\n",
    "                            print(f\"‚úÖ Video {i+1} saved: {output_path.name}\")\n",
    "                            \n",
    "                print(f\"\\nüéâ Batch generation complete! {len(saved_videos)} videos saved.\")\n",
    "                \n",
    "                # Display first video as preview\n",
    "                if saved_videos:\n",
    "                    print(\"\\nüìπ Preview of first video:\")\n",
    "                    self.display_video(saved_videos[0])\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Batch generation error: {str(e)}\")\n",
    "                \n",
    "    def display_video(self, video_path: str):\n",
    "        \"\"\"Display a video in the output\"\"\"\n",
    "        try:\n",
    "            video_widget = Video.from_file(video_path, width=640, height=360)\n",
    "            display(video_widget)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not display video: {str(e)}\")\n",
    "            print(f\"Video saved at: {video_path}\")\n",
    "            \n",
    "    def clear_output(self, button):\n",
    "        \"\"\"Clear the output widget\"\"\"\n",
    "        with self.output_widget:\n",
    "            clear_output()\n",
    "            print(\"üóëÔ∏è Output cleared\")\n",
    "\n",
    "# Create and display the UI\n",
    "ui = VideoGeneratorUI(video_pipeline)\n",
    "ui.display_ui()\n",
    "\n",
    "print(\"\\nüé® Enhanced UI loaded! Ready to generate videos with advanced scene analysis.\")\n",
    "print(\"üéØ Try different prompt types: sunset, ocean, forest, city, mountains, space!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examples_header"
   },
   "source": [
    "## üéØ Step 6: Example Usage & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "example_usage"
   },
   "outputs": [],
   "source": [
    "# Example prompts optimized for different scene types\n",
    "example_prompts = [\n",
    "    \"A beautiful sunset over mountains with golden light and rolling clouds\",\n",
    "    \"Ocean waves crashing on a peaceful beach with seagulls flying overhead\",\n",
    "    \"A peaceful forest with tall swaying trees and dappled sunlight\",\n",
    "    \"City skyline at night with twinkling lights and moving traffic\",\n",
    "    \"Majestic mountain landscape with snow-capped peaks and morning mist\",\n",
    "    \"Deep space scene with twinkling stars and a beautiful planet\",\n",
    "    \"Flowing river through a green valley with butterflies\",\n",
    "    \"Desert landscape with golden sand dunes at dawn\"\n",
    "]\n",
    "\n",
    "# Display example prompts\n",
    "print(\"üéØ Example Prompts for Different Scene Types:\")\n",
    "for i, prompt in enumerate(example_prompts, 1):\n",
    "    print(f\"\\n{i}. {prompt}\")\n",
    "\n",
    "# Quick test function\n",
    "def quick_test():\n",
    "    \"\"\"Quick test of the video generation pipeline\"\"\"\n",
    "    print(\"\\nüß™ Running quick test...\")\n",
    "    \n",
    "    try:\n",
    "        # Load pipeline\n",
    "        video_pipeline.load_pipeline()\n",
    "        \n",
    "        # Generate a short test video\n",
    "        test_frames, test_settings = video_pipeline.generate_video(\n",
    "            prompt=\"A beautiful sunset over mountains\",\n",
    "            width=480,\n",
    "            height=320,\n",
    "            num_frames=48,  # 2 seconds at 24fps\n",
    "            fps=24,\n",
    "            num_inference_steps=25,  # Faster for testing\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        # Save test video\n",
    "        test_path = \"/tmp/test_video.mp4\"\n",
    "        success = video_pipeline.save_video(test_frames, test_path, fps=24)\n",
    "        \n",
    "        if success:\n",
    "            print(f\"‚úÖ Test successful! Video saved to: {test_path}\")\n",
    "            \n",
    "            # Display test video\n",
    "            from IPython.display import Video\n",
    "            display(Video(test_path, width=480, height=320))\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(\"‚ùå Test failed: Could not save video\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Memory status function\n",
    "def check_memory_status():\n",
    "    \"\"\"Check current memory usage\"\"\"\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "            cached = torch.cuda.memory_reserved(0) / 1024**3\n",
    "            total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "            \n",
    "            print(f\"üß† GPU Memory Status:\")\n",
    "            print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "            print(f\"  Cached: {cached:.2f} GB\")\n",
    "            print(f\"  Total: {total:.2f} GB\")\n",
    "            print(f\"  Free: {total - cached:.2f} GB\")\n",
    "        else:\n",
    "            print(\"‚ÑπÔ∏è Using CPU mode - no GPU memory stats\")\n",
    "            \n",
    "        # RAM status\n",
    "        import psutil\n",
    "        memory = psutil.virtual_memory()\n",
    "        print(f\"\\nüß† RAM Status:\")\n",
    "        print(f\"  Used: {memory.used / 1024**3:.2f} GB\")\n",
    "        print(f\"  Available: {memory.available / 1024**3:.2f} GB\")\n",
    "        print(f\"  Total: {memory.total / 1024**3:.2f} GB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error checking memory: {str(e)}\")\n",
    "\n",
    "# Check memory status\n",
    "check_memory_status()\n",
    "\n",
    "print(\"\\nüéØ Ready for testing! Use the UI above or run quick_test() for a quick test.\")\n",
    "print(\"üé¨ The pipeline supports advanced scene analysis for different content types!\")\n",
    "print(\"‚úÖ All compatibility issues have been resolved!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}