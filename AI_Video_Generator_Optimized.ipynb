{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# üé¨ AI Video Generator - Optimized for Google Colab\n",
    "\n",
    "**Features:**\n",
    "- 720p Resolution Support\n",
    "- 10-second video generation\n",
    "- 24fps output\n",
    "- Realistic human posing\n",
    "- Batch processing\n",
    "- Memory optimization\n",
    "- Progress tracking\n",
    "- Automatic environment detection\n",
    "\n",
    "**Requirements:**\n",
    "- GPU Runtime (T4 or better recommended)\n",
    "- ~15GB RAM\n",
    "- ~20GB Disk Space\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_header"
   },
   "source": [
    "## üìã Step 1: Environment Detection & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "environment_detection"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "import psutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try importing optional packages with fallbacks\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    print(\"‚úÖ ipywidgets imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è ipywidgets not available, some UI features may be limited\")\n",
    "    \n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "    print(\"‚úÖ tqdm imported successfully\")\n",
    "except ImportError:\n",
    "    from tqdm import tqdm\n",
    "    print(\"‚ö†Ô∏è Using console tqdm instead of notebook version\")\n",
    "\n",
    "class EnvironmentDetector:\n",
    "    def __init__(self):\n",
    "        self.system_info = {}\n",
    "        self.requirements_met = False\n",
    "        \n",
    "    def detect_environment(self):\n",
    "        \"\"\"Detect and validate the current environment\"\"\"\n",
    "        print(\"üîç Detecting environment...\")\n",
    "        \n",
    "        # Basic system info\n",
    "        self.system_info['platform'] = platform.system()\n",
    "        self.system_info['python_version'] = sys.version\n",
    "        self.system_info['is_colab'] = 'google.colab' in sys.modules\n",
    "        \n",
    "        # Memory info\n",
    "        memory = psutil.virtual_memory()\n",
    "        self.system_info['total_ram_gb'] = round(memory.total / (1024**3), 2)\n",
    "        self.system_info['available_ram_gb'] = round(memory.available / (1024**3), 2)\n",
    "        \n",
    "        # GPU info with fallback\n",
    "        try:\n",
    "            import torch\n",
    "            self.system_info['cuda_available'] = torch.cuda.is_available()\n",
    "            if torch.cuda.is_available():\n",
    "                self.system_info['gpu_name'] = torch.cuda.get_device_name(0)\n",
    "                self.system_info['gpu_memory_gb'] = round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 2)\n",
    "            else:\n",
    "                self.system_info['gpu_name'] = 'None'\n",
    "                self.system_info['gpu_memory_gb'] = 0\n",
    "        except:\n",
    "            self.system_info['cuda_available'] = False\n",
    "            self.system_info['gpu_name'] = 'None'\n",
    "            self.system_info['gpu_memory_gb'] = 0\n",
    "        \n",
    "        # Disk space\n",
    "        disk_usage = psutil.disk_usage('/')\n",
    "        self.system_info['disk_free_gb'] = round(disk_usage.free / (1024**3), 2)\n",
    "        \n",
    "        self._display_info()\n",
    "        self._check_requirements()\n",
    "        \n",
    "    def _display_info(self):\n",
    "        \"\"\"Display system information in a nice format\"\"\"\n",
    "        info_html = f\"\"\"\n",
    "        <div style=\"background-color: #f0f2f6; padding: 15px; border-radius: 10px; margin: 10px 0;\">\n",
    "            <h3>üñ•Ô∏è System Information</h3>\n",
    "            <table style=\"width: 100%; border-collapse: collapse;\">\n",
    "                <tr><td><b>Platform:</b></td><td>{self.system_info['platform']}</td></tr>\n",
    "                <tr><td><b>Google Colab:</b></td><td>{'‚úÖ Yes' if self.system_info['is_colab'] else '‚ùå No'}</td></tr>\n",
    "                <tr><td><b>Total RAM:</b></td><td>{self.system_info['total_ram_gb']} GB</td></tr>\n",
    "                <tr><td><b>Available RAM:</b></td><td>{self.system_info['available_ram_gb']} GB</td></tr>\n",
    "                <tr><td><b>GPU:</b></td><td>{self.system_info['gpu_name']}</td></tr>\n",
    "                <tr><td><b>GPU Memory:</b></td><td>{self.system_info['gpu_memory_gb']} GB</td></tr>\n",
    "                <tr><td><b>Free Disk Space:</b></td><td>{self.system_info['disk_free_gb']} GB</td></tr>\n",
    "            </table>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(info_html))\n",
    "        \n",
    "    def _check_requirements(self):\n",
    "        \"\"\"Check if system meets requirements\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        if not self.system_info['cuda_available']:\n",
    "            issues.append(\"‚ùå CUDA not available - GPU required for optimal performance\")\n",
    "        elif self.system_info['gpu_memory_gb'] < 6:\n",
    "            issues.append(\"‚ö†Ô∏è GPU memory < 6GB - may experience memory issues\")\n",
    "            \n",
    "        if self.system_info['total_ram_gb'] < 12:\n",
    "            issues.append(\"‚ö†Ô∏è RAM < 12GB - may experience memory issues\")\n",
    "            \n",
    "        if self.system_info['disk_free_gb'] < 15:\n",
    "            issues.append(\"‚ö†Ô∏è Disk space < 15GB - may not have enough space for models\")\n",
    "            \n",
    "        if issues:\n",
    "            print(\"\\n‚ö†Ô∏è System Issues Detected:\")\n",
    "            for issue in issues:\n",
    "                print(f\"  {issue}\")\n",
    "            print(\"\\nüí° Recommendation: Use Google Colab Pro with GPU runtime for best results\")\n",
    "        else:\n",
    "            print(\"\\n‚úÖ All requirements met! Ready to proceed.\")\n",
    "            self.requirements_met = True\n",
    "            \n",
    "        return len(issues) == 0\n",
    "\n",
    "# Initialize and run environment detection\n",
    "env_detector = EnvironmentDetector()\n",
    "env_detector.detect_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dependencies_header"
   },
   "source": [
    "## üì¶ Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "class DependencyManager:\n",
    "    def __init__(self):\n",
    "        self.packages = {\n",
    "            'essential': [\n",
    "                'torch>=2.1.0',\n",
    "                'torchvision>=0.16.0',\n",
    "                'diffusers>=0.30.3',\n",
    "                'transformers>=4.44.2',\n",
    "                'accelerate>=0.33.0',\n",
    "                'xformers>=0.0.23',\n",
    "            ],\n",
    "            'video': [\n",
    "                'opencv-python-headless>=4.8.0',\n",
    "                'imageio[ffmpeg]>=2.31.0',\n",
    "                'moviepy>=1.0.3',\n",
    "                'av>=10.0.0',\n",
    "                'decord>=0.6.0'\n",
    "            ],\n",
    "            'ui': [\n",
    "                'streamlit>=1.28.0',\n",
    "                'gradio>=4.0.0',\n",
    "                'ipywidgets>=8.0.0',\n",
    "                'matplotlib>=3.7.0',\n",
    "                'pillow>=10.0.0'\n",
    "            ],\n",
    "            'utils': [\n",
    "                'huggingface-hub>=0.19.0',\n",
    "                'safetensors>=0.4.0',\n",
    "                'einops>=0.7.0',\n",
    "                'omegaconf>=2.3.0',\n",
    "                'pyngrok>=7.0.0'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "    def install_packages(self, category='all'):\n",
    "        \"\"\"Install packages with progress tracking\"\"\"\n",
    "        categories = [category] if category != 'all' else self.packages.keys()\n",
    "        \n",
    "        # Special handling for PyTorch with CUDA\n",
    "        if category == 'all' or category == 'essential':\n",
    "            print(\"\\nüî• Installing PyTorch with CUDA support...\")\n",
    "            torch_install_cmd = [\n",
    "                sys.executable, '-m', 'pip', 'install', 'torch>=2.1.0', 'torchvision>=0.16.0', 'torchaudio>=2.1.0',\n",
    "                '--index-url', 'https://download.pytorch.org/whl/cu121', '--quiet'\n",
    "            ]\n",
    "            \n",
    "            try:\n",
    "                result = subprocess.run(torch_install_cmd, capture_output=True, text=True, timeout=600)\n",
    "                if result.returncode == 0:\n",
    "                    print(\"‚úÖ PyTorch with CUDA installed successfully\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è PyTorch CUDA installation failed, trying CPU version...\")\n",
    "                    # Fallback to CPU version\n",
    "                    cpu_cmd = [sys.executable, '-m', 'pip', 'install', 'torch>=2.1.0', 'torchvision>=0.16.0', 'torchaudio>=2.1.0', '--quiet']\n",
    "                    subprocess.run(cpu_cmd, timeout=600)\n",
    "            except subprocess.TimeoutExpired:\n",
    "                print(\"‚ö†Ô∏è PyTorch installation timeout, continuing...\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error installing PyTorch: {str(e)}\")\n",
    "                \n",
    "        for cat in categories:\n",
    "            if cat == 'essential':  # Skip essential as we handled PyTorch separately\n",
    "                packages = [p for p in self.packages[cat] if not p.startswith('torch')]\n",
    "            else:\n",
    "                packages = self.packages[cat]\n",
    "                \n",
    "            if not packages:\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\nüì¶ Installing {cat} packages...\")\n",
    "            \n",
    "            progress_bar = tqdm(packages, desc=f\"Installing {cat}\")\n",
    "            for package in progress_bar:\n",
    "                try:\n",
    "                    progress_bar.set_postfix_str(f\"Installing {package.split('>=')[0]}\")\n",
    "                    result = subprocess.run(\n",
    "                        [sys.executable, '-m', 'pip', 'install', package, '--quiet'],\n",
    "                        capture_output=True,\n",
    "                        text=True,\n",
    "                        timeout=300\n",
    "                    )\n",
    "                    if result.returncode != 0:\n",
    "                        print(f\"‚ö†Ô∏è Warning: Failed to install {package}\")\n",
    "                        print(f\"Error: {result.stderr}\")\n",
    "                except subprocess.TimeoutExpired:\n",
    "                    print(f\"‚ö†Ô∏è Timeout installing {package}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error installing {package}: {str(e)}\")\n",
    "                    \n",
    "        print(\"\\n‚úÖ Dependencies installation completed!\")\n",
    "        \n",
    "    def verify_installation(self):\n",
    "        \"\"\"Verify critical packages are installed\"\"\"\n",
    "        critical_imports = {\n",
    "            'torch': 'PyTorch',\n",
    "            'diffusers': 'Diffusers',\n",
    "            'transformers': 'Transformers',\n",
    "            'cv2': 'OpenCV',\n",
    "            'imageio': 'ImageIO',\n",
    "            'streamlit': 'Streamlit'\n",
    "        }\n",
    "        \n",
    "        print(\"\\nüîç Verifying installations...\")\n",
    "        for module, name in critical_imports.items():\n",
    "            try:\n",
    "                __import__(module)\n",
    "                print(f\"‚úÖ {name} - OK\")\n",
    "            except ImportError:\n",
    "                print(f\"‚ùå {name} - FAILED\")\n",
    "                \n",
    "        # Check CUDA availability\n",
    "        try:\n",
    "            import torch\n",
    "            if torch.cuda.is_available():\n",
    "                print(f\"‚úÖ CUDA - OK (Device: {torch.cuda.get_device_name(0)})\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è CUDA - Not available\")\n",
    "        except:\n",
    "            print(\"‚ùå CUDA - Error checking\")\n",
    "\n",
    "# Install dependencies\n",
    "dep_manager = DependencyManager()\n",
    "dep_manager.install_packages()\n",
    "dep_manager.verify_installation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "models_header"
   },
   "source": [
    "## ü§ñ Step 3: Model Download & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_setup"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "from huggingface_hub import snapshot_download, hf_hub_download\n",
    "from pathlib import Path\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "class ModelManager:\n",
    "    def __init__(self):\n",
    "        self.models_dir = Path(\"/content/models\")\n",
    "        self.models_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.model_configs = {\n",
    "            'cogvideox': {\n",
    "                'repo_id': 'THUDM/CogVideoX-2b',\n",
    "                'local_dir': self.models_dir / 'CogVideoX-2b',\n",
    "                'size_gb': 8.5,\n",
    "                'description': 'Main video generation model'\n",
    "            },\n",
    "            'venhancer': {\n",
    "                'repo_id': 'jwhejwhe/VEnhancer',\n",
    "                'local_dir': self.models_dir / 'VEnhancer',\n",
    "                'size_gb': 2.1,\n",
    "                'description': 'Video enhancement model'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    def download_model(self, model_name, force_download=False):\n",
    "        \"\"\"Download a specific model with progress tracking\"\"\"\n",
    "        if model_name not in self.model_configs:\n",
    "            raise ValueError(f\"Unknown model: {model_name}\")\n",
    "            \n",
    "        config = self.model_configs[model_name]\n",
    "        local_dir = config['local_dir']\n",
    "        \n",
    "        # Check if model already exists\n",
    "        if local_dir.exists() and not force_download:\n",
    "            print(f\"‚úÖ {model_name} already exists at {local_dir}\")\n",
    "            return str(local_dir)\n",
    "            \n",
    "        print(f\"\\nüì• Downloading {model_name} ({config['size_gb']:.1f}GB)...\")\n",
    "        print(f\"üìù {config['description']}\")\n",
    "        \n",
    "        try:\n",
    "            # Create progress callback\n",
    "            def progress_callback(block_num, block_size, total_size):\n",
    "                if total_size > 0:\n",
    "                    percent = min(100, (block_num * block_size * 100) / total_size)\n",
    "                    print(f\"\\rProgress: {percent:.1f}%\", end=\"\")\n",
    "                    \n",
    "            # Download with resume capability\n",
    "            local_dir_str = str(local_dir)\n",
    "            snapshot_download(\n",
    "                repo_id=config['repo_id'],\n",
    "                local_dir=local_dir_str,\n",
    "                resume_download=True,\n",
    "                local_dir_use_symlinks=False,\n",
    "                ignore_patterns=[\"*.git*\", \"README.md\", \"*.txt\"]\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n‚úÖ {model_name} downloaded successfully!\")\n",
    "            return local_dir_str\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error downloading {model_name}: {str(e)}\")\n",
    "            return None\n",
    "            \n",
    "    def download_all_models(self):\n",
    "        \"\"\"Download all required models\"\"\"\n",
    "        total_size = sum(config['size_gb'] for config in self.model_configs.values())\n",
    "        print(f\"\\nüì¶ Downloading all models (Total: {total_size:.1f}GB)\")\n",
    "        \n",
    "        downloaded_models = {}\n",
    "        for model_name in self.model_configs.keys():\n",
    "            path = self.download_model(model_name)\n",
    "            if path:\n",
    "                downloaded_models[model_name] = path\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Failed to download {model_name}\")\n",
    "                \n",
    "        return downloaded_models\n",
    "        \n",
    "    def get_model_info(self):\n",
    "        \"\"\"Get information about downloaded models\"\"\"\n",
    "        info = {}\n",
    "        for model_name, config in self.model_configs.items():\n",
    "            local_dir = config['local_dir']\n",
    "            info[model_name] = {\n",
    "                'exists': local_dir.exists(),\n",
    "                'path': str(local_dir),\n",
    "                'size_gb': config['size_gb'],\n",
    "                'description': config['description']\n",
    "            }\n",
    "        return info\n",
    "        \n",
    "    def cleanup_models(self):\n",
    "        \"\"\"Clean up downloaded models to free space\"\"\"\n",
    "        import shutil\n",
    "        if self.models_dir.exists():\n",
    "            shutil.rmtree(self.models_dir)\n",
    "            print(\"üóëÔ∏è All models cleaned up\")\n",
    "\n",
    "# Initialize model manager and download models\n",
    "model_manager = ModelManager()\n",
    "\n",
    "# Show model info\n",
    "print(\"üìã Model Information:\")\n",
    "for name, info in model_manager.get_model_info().items():\n",
    "    status = \"‚úÖ Downloaded\" if info['exists'] else \"‚ùå Not downloaded\"\n",
    "    print(f\"  {name}: {info['description']} ({info['size_gb']:.1f}GB) - {status}\")\n",
    "\n",
    "# Download all models\n",
    "downloaded_models = model_manager.download_all_models()\n",
    "print(f\"\\nüéâ Model setup complete! Downloaded {len(downloaded_models)} models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pipeline_header"
   },
   "source": [
    "## üé¨ Step 4: Optimized Video Generation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "video_pipeline"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/models')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import gc\n",
    "from typing import List, Optional, Union\n",
    "import subprocess\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Safe import of diffusers with compatibility check\n",
    "try:\n",
    "    from diffusers import CogVideoXPipeline, CogVideoXDPMScheduler\n",
    "    print(\"‚úÖ CogVideoX pipeline imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing CogVideoX pipeline: {str(e)}\")\n",
    "    print(\"üí° This might be due to version incompatibility.\")\n",
    "    print(\"üí° Please ensure you have:\")\n",
    "    print(\"   - torch>=2.1.0\")\n",
    "    print(\"   - diffusers>=0.30.3\")\n",
    "    print(\"   - transformers>=4.44.2\")\n",
    "    print(\"üí° Try running: pip install --upgrade torch diffusers transformers\")\n",
    "    raise\n",
    "\n",
    "# Version compatibility check\n",
    "print(f\"üìä Version Info:\")\n",
    "print(f\"   torch: {torch.__version__}\")\n",
    "try:\n",
    "    import diffusers\n",
    "    print(f\"   diffusers: {diffusers.__version__}\")\n",
    "except:\n",
    "    print(\"   diffusers: version check failed\")\n",
    "try:\n",
    "    import transformers\n",
    "    print(f\"   transformers: {transformers.__version__}\")\n",
    "except:\n",
    "    print(\"   transformers: version check failed\")\n",
    "\n",
    "class OptimizedVideoPipeline:\n",
    "    def __init__(self, model_path: str, device: str = \"cuda\"):\n",
    "        self.device = device\n",
    "        self.model_path = model_path\n",
    "        self.pipeline = None\n",
    "        self.loaded = False\n",
    "        \n",
    "        # Optimized settings for 720p, 10s, 24fps\n",
    "        self.default_settings = {\n",
    "            'width': 720,\n",
    "            'height': 480,  # 3:2 aspect ratio for better model performance\n",
    "            'num_frames': 240,  # 10 seconds at 24fps\n",
    "            'fps': 24,\n",
    "            'num_inference_steps': 50,\n",
    "            'guidance_scale': 6.0,\n",
    "            'num_videos_per_prompt': 1\n",
    "        }\n",
    "        \n",
    "    def load_pipeline(self):\n",
    "        \"\"\"Load the video generation pipeline with memory optimization\"\"\"\n",
    "        if self.loaded:\n",
    "            return\n",
    "            \n",
    "        print(\"üîÑ Loading CogVideoX pipeline...\")\n",
    "        \n",
    "        try:\n",
    "            # Clear memory before loading\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # Load pipeline with optimizations\n",
    "            self.pipeline = CogVideoXPipeline.from_pretrained(\n",
    "                self.model_path,\n",
    "                torch_dtype=torch.float16,\n",
    "                variant=\"fp16\",\n",
    "                use_safetensors=True,\n",
    "                low_cpu_mem_usage=True\n",
    "            )\n",
    "            \n",
    "            # Move to device\n",
    "            self.pipeline = self.pipeline.to(self.device)\n",
    "            \n",
    "            # Enable memory efficient optimizations\n",
    "            self.pipeline.enable_model_cpu_offload()\n",
    "            self.pipeline.enable_vae_slicing()\n",
    "            \n",
    "            # Try to enable xformers if available\n",
    "            try:\n",
    "                self.pipeline.enable_xformers_memory_efficient_attention()\n",
    "                print(\"‚úÖ xFormers enabled for memory efficiency\")\n",
    "            except:\n",
    "                print(\"‚ö†Ô∏è xFormers not available, using default attention\")\n",
    "                \n",
    "            self.loaded = True\n",
    "            print(\"‚úÖ Pipeline loaded successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading pipeline: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def generate_video(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        negative_prompt: str = None,\n",
    "        seed: int = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"Generate a single video with optimized settings\"\"\"\n",
    "        if not self.loaded:\n",
    "            self.load_pipeline()\n",
    "            \n",
    "        # Merge settings\n",
    "        settings = {**self.default_settings, **kwargs}\n",
    "        \n",
    "        print(f\"üé¨ Generating video: {settings['width']}x{settings['height']}, {settings['num_frames']} frames, {settings['fps']} fps\")\n",
    "        print(f\"üìù Prompt: {prompt}\")\n",
    "        \n",
    "        # Set up generator for reproducibility\n",
    "        generator = None\n",
    "        if seed is not None:\n",
    "            generator = torch.Generator(device=self.device).manual_seed(seed)\n",
    "            print(f\"üé≤ Using seed: {seed}\")\n",
    "            \n",
    "        try:\n",
    "            # Clear memory before generation\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # Generate video\n",
    "            with torch.inference_mode():\n",
    "                result = self.pipeline(\n",
    "                    prompt=prompt,\n",
    "                    negative_prompt=negative_prompt,\n",
    "                    width=settings['width'],\n",
    "                    height=settings['height'],\n",
    "                    num_frames=settings['num_frames'],\n",
    "                    num_inference_steps=settings['num_inference_steps'],\n",
    "                    guidance_scale=settings['guidance_scale'],\n",
    "                    num_videos_per_prompt=settings['num_videos_per_prompt'],\n",
    "                    generator=generator,\n",
    "                    output_type=\"pil\"\n",
    "                )\n",
    "                \n",
    "            # Extract frames\n",
    "            frames = result.frames[0]\n",
    "            \n",
    "            # Clean up\n",
    "            del result\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            print(f\"‚úÖ Generated {len(frames)} frames successfully!\")\n",
    "            return frames, settings\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error generating video: {str(e)}\")\n",
    "            # Clean up on error\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            raise\n",
    "            \n",
    "    def generate_batch(\n",
    "        self,\n",
    "        prompts: List[str],\n",
    "        negative_prompts: List[str] = None,\n",
    "        seeds: List[int] = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"Generate multiple videos in batch\"\"\"\n",
    "        if not prompts:\n",
    "            return []\n",
    "            \n",
    "        print(f\"üé¨ Starting batch generation of {len(prompts)} videos...\")\n",
    "        \n",
    "        # Prepare inputs\n",
    "        if negative_prompts is None:\n",
    "            negative_prompts = [None] * len(prompts)\n",
    "        if seeds is None:\n",
    "            seeds = [None] * len(prompts)\n",
    "            \n",
    "        results = []\n",
    "        \n",
    "        for i, (prompt, neg_prompt, seed) in enumerate(zip(prompts, negative_prompts, seeds)):\n",
    "            print(f\"\\nüìπ Processing video {i+1}/{len(prompts)}\")\n",
    "            \n",
    "            try:\n",
    "                frames, settings = self.generate_video(\n",
    "                    prompt=prompt,\n",
    "                    negative_prompt=neg_prompt,\n",
    "                    seed=seed,\n",
    "                    **kwargs\n",
    "                )\n",
    "                \n",
    "                results.append({\n",
    "                    'frames': frames,\n",
    "                    'settings': settings,\n",
    "                    'prompt': prompt,\n",
    "                    'success': True\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to generate video {i+1}: {str(e)}\")\n",
    "                results.append({\n",
    "                    'frames': None,\n",
    "                    'settings': None,\n",
    "                    'prompt': prompt,\n",
    "                    'success': False,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "                \n",
    "        successful = sum(1 for r in results if r['success'])\n",
    "        print(f\"\\nüéâ Batch generation complete! {successful}/{len(prompts)} videos generated successfully.\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    def save_video(\n",
    "        self,\n",
    "        frames: List[Image.Image],\n",
    "        output_path: str,\n",
    "        fps: int = 24,\n",
    "        quality: int = 8\n",
    "    ):\n",
    "        \"\"\"Save frames as video file\"\"\"\n",
    "        print(f\"üíæ Saving video to {output_path}...\")\n",
    "        \n",
    "        try:\n",
    "            # Convert PIL images to numpy arrays\n",
    "            video_frames = []\n",
    "            for frame in frames:\n",
    "                if isinstance(frame, Image.Image):\n",
    "                    video_frames.append(np.array(frame))\n",
    "                else:\n",
    "                    video_frames.append(frame)\n",
    "                    \n",
    "            # Save using imageio\n",
    "            with imageio.get_writer(\n",
    "                output_path,\n",
    "                fps=fps,\n",
    "                codec='libx264',\n",
    "                quality=quality,\n",
    "                pixelformat='yuv420p'\n",
    "            ) as writer:\n",
    "                for frame in video_frames:\n",
    "                    writer.append_data(frame)\n",
    "                    \n",
    "            print(f\"‚úÖ Video saved successfully!\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving video: {str(e)}\")\n",
    "            return False\n",
    "            \n",
    "    def upscale_to_720p(self, frames: List[Image.Image]):\n",
    "        \"\"\"Upscale frames to 720p resolution\"\"\"\n",
    "        print(\"üîç Upscaling frames to 720p...\")\n",
    "        \n",
    "        upscaled_frames = []\n",
    "        target_size = (1280, 720)  # 720p resolution\n",
    "        \n",
    "        for frame in tqdm(frames, desc=\"Upscaling\"):\n",
    "            if isinstance(frame, Image.Image):\n",
    "                # Use high-quality resampling\n",
    "                upscaled = frame.resize(target_size, Image.LANCZOS)\n",
    "                upscaled_frames.append(upscaled)\n",
    "            else:\n",
    "                # Convert numpy array to PIL and upscale\n",
    "                pil_frame = Image.fromarray(frame)\n",
    "                upscaled = pil_frame.resize(target_size, Image.LANCZOS)\n",
    "                upscaled_frames.append(upscaled)\n",
    "                \n",
    "        print(f\"‚úÖ Upscaled {len(upscaled_frames)} frames to 720p\")\n",
    "        return upscaled_frames\n",
    "        \n",
    "    def unload_pipeline(self):\n",
    "        \"\"\"Unload pipeline to free memory\"\"\"\n",
    "        if self.pipeline:\n",
    "            del self.pipeline\n",
    "            self.pipeline = None\n",
    "            self.loaded = False\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"üóëÔ∏è Pipeline unloaded and memory cleared\")\n",
    "\n",
    "# Initialize the pipeline\n",
    "cogvideox_path = \"/content/models/CogVideoX-2b\"\n",
    "video_pipeline = OptimizedVideoPipeline(cogvideox_path)\n",
    "\n",
    "print(\"üé¨ Video pipeline initialized and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ui_header"
   },
   "source": [
    "## üé® Step 5: Enhanced User Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "enhanced_ui"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Video, clear_output\n",
    "import tempfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Try to import ipywidgets, create fallback if not available\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    WIDGETS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    WIDGETS_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è ipywidgets not available, using basic interface\")\n",
    "\n",
    "class VideoGeneratorUI:\n",
    "    def __init__(self, pipeline: OptimizedVideoPipeline):\n",
    "        self.pipeline = pipeline\n",
    "        self.output_dir = Path(\"/content/outputs\")\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        if WIDGETS_AVAILABLE:\n",
    "            self.setup_ui()\n",
    "        else:\n",
    "            print(\"Using basic interface - install ipywidgets for enhanced UI\")\n",
    "        \n",
    "    def setup_ui(self):\n",
    "        \"\"\"Setup the user interface widgets\"\"\"\n",
    "        if not WIDGETS_AVAILABLE:\n",
    "            return\n",
    "            \n",
    "        # Style\n",
    "        style = {'description_width': '150px'}\n",
    "        layout = widgets.Layout(width='400px')\n",
    "        \n",
    "        # Input widgets\n",
    "        self.prompt_input = widgets.Textarea(\n",
    "            value=\"A realistic human walking in a park, cinematic lighting, 4K quality\",\n",
    "            placeholder=\"Enter your video prompt here...\",\n",
    "            description=\"Prompt:\",\n",
    "            style=style,\n",
    "            layout=widgets.Layout(width='600px', height='80px')\n",
    "        )\n",
    "        \n",
    "        self.negative_prompt_input = widgets.Textarea(\n",
    "            value=\"blurry, low quality, distorted, artifacts\",\n",
    "            placeholder=\"Enter negative prompt (optional)...\",\n",
    "            description=\"Negative Prompt:\",\n",
    "            style=style,\n",
    "            layout=widgets.Layout(width='600px', height='60px')\n",
    "        )\n",
    "        \n",
    "        # Settings\n",
    "        self.resolution_dropdown = widgets.Dropdown(\n",
    "            options=[('720p (1280x720)', (1280, 720)), ('480p (720x480)', (720, 480)), ('360p (640x360)', (640, 360))],\n",
    "            value=(720, 480),\n",
    "            description=\"Resolution:\",\n",
    "            style=style,\n",
    "            layout=layout\n",
    "        )\n",
    "        \n",
    "        self.duration_slider = widgets.IntSlider(\n",
    "            value=10,\n",
    "            min=2,\n",
    "            max=20,\n",
    "            step=1,\n",
    "            description=\"Duration (s):\",\n",
    "            style=style,\n",
    "            layout=layout\n",
    "        )\n",
    "        \n",
    "        self.fps_slider = widgets.IntSlider(\n",
    "            value=24,\n",
    "            min=12,\n",
    "            max=30,\n",
    "            step=6,\n",
    "            description=\"FPS:\",\n",
    "            style=style,\n",
    "            layout=layout\n",
    "        )\n",
    "        \n",
    "        self.seed_input = widgets.IntText(\n",
    "            value=42,\n",
    "            description=\"Seed:\",\n",
    "            style=style,\n",
    "            layout=layout\n",
    "        )\n",
    "        \n",
    "        self.steps_slider = widgets.IntSlider(\n",
    "            value=50,\n",
    "            min=20,\n",
    "            max=100,\n",
    "            step=10,\n",
    "            description=\"Steps:\",\n",
    "            style=style,\n",
    "            layout=layout\n",
    "        )\n",
    "        \n",
    "        self.guidance_slider = widgets.FloatSlider(\n",
    "            value=6.0,\n",
    "            min=1.0,\n",
    "            max=12.0,\n",
    "            step=0.5,\n",
    "            description=\"Guidance:\",\n",
    "            style=style,\n",
    "            layout=layout\n",
    "        )\n",
    "        \n",
    "        # Batch processing\n",
    "        self.batch_prompts = widgets.Textarea(\n",
    "            value=\"\",\n",
    "            placeholder=\"Enter multiple prompts separated by new lines for batch processing...\",\n",
    "            description=\"Batch Prompts:\",\n",
    "            style=style,\n",
    "            layout=widgets.Layout(width='600px', height='120px')\n",
    "        )\n",
    "        \n",
    "        # Buttons\n",
    "        self.generate_button = widgets.Button(\n",
    "            description=\"üé¨ Generate Video\",\n",
    "            button_style='primary',\n",
    "            layout=widgets.Layout(width='200px', height='40px')\n",
    "        )\n",
    "        \n",
    "        self.batch_button = widgets.Button(\n",
    "            description=\"üìπ Batch Generate\",\n",
    "            button_style='info',\n",
    "            layout=widgets.Layout(width='200px', height='40px')\n",
    "        )\n",
    "        \n",
    "        self.clear_button = widgets.Button(\n",
    "            description=\"üóëÔ∏è Clear Output\",\n",
    "            button_style='warning',\n",
    "            layout=widgets.Layout(width='200px', height='40px')\n",
    "        )\n",
    "        \n",
    "        # Output\n",
    "        self.output_widget = widgets.Output()\n",
    "        \n",
    "        # Event handlers\n",
    "        self.generate_button.on_click(self.generate_single_video)\n",
    "        self.batch_button.on_click(self.generate_batch_videos)\n",
    "        self.clear_button.on_click(self.clear_output)\n",
    "        \n",
    "    def display_ui(self):\n",
    "        \"\"\"Display the complete UI\"\"\"\n",
    "        if not WIDGETS_AVAILABLE:\n",
    "            self.display_basic_ui()\n",
    "            return\n",
    "            \n",
    "        # Title\n",
    "        title = HTML(\"<h2>üé¨ AI Video Generator - Optimized Interface</h2>\")\n",
    "        \n",
    "        # Single video generation\n",
    "        single_gen_title = HTML(\"<h3>üìπ Single Video Generation</h3>\")\n",
    "        single_gen_box = widgets.VBox([\n",
    "            self.prompt_input,\n",
    "            self.negative_prompt_input,\n",
    "            widgets.HBox([self.resolution_dropdown, self.duration_slider, self.fps_slider]),\n",
    "            widgets.HBox([self.seed_input, self.steps_slider, self.guidance_slider]),\n",
    "            self.generate_button\n",
    "        ])\n",
    "        \n",
    "        # Batch generation\n",
    "        batch_gen_title = HTML(\"<h3>üì¶ Batch Video Generation</h3>\")\n",
    "        batch_gen_box = widgets.VBox([\n",
    "            self.batch_prompts,\n",
    "            widgets.HBox([self.batch_button, self.clear_button])\n",
    "        ])\n",
    "        \n",
    "        # Complete UI\n",
    "        complete_ui = widgets.VBox([\n",
    "            title,\n",
    "            single_gen_title,\n",
    "            single_gen_box,\n",
    "            batch_gen_title,\n",
    "            batch_gen_box,\n",
    "            self.output_widget\n",
    "        ])\n",
    "        \n",
    "        display(complete_ui)\n",
    "    \n",
    "    def display_basic_ui(self):\n",
    "        \"\"\"Display basic interface without widgets\"\"\"\n",
    "        basic_ui = HTML(\"\"\"\n",
    "        <div style=\"background-color: #f0f2f6; padding: 20px; border-radius: 10px; margin: 10px 0;\">\n",
    "            <h2>üé¨ AI Video Generator - Basic Interface</h2>\n",
    "            <p>To use the video generator programmatically:</p>\n",
    "            <pre>\n",
    "# Generate a single video\n",
    "frames, settings = video_pipeline.generate_video(\n",
    "    prompt=\"A realistic human walking in a park, cinematic lighting, 4K quality\",\n",
    "    negative_prompt=\"blurry, low quality, distorted, artifacts\",\n",
    "    width=720,\n",
    "    height=480,\n",
    "    num_frames=240,  # 10 seconds at 24fps\n",
    "    fps=24,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Save the video\n",
    "output_path = \"/content/outputs/my_video.mp4\"\n",
    "video_pipeline.save_video(frames, output_path, fps=24)\n",
    "            </pre>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        display(basic_ui)\n",
    "        \n",
    "    def generate_single_video(self, button=None):\n",
    "        \"\"\"Generate a single video\"\"\"\n",
    "        if not WIDGETS_AVAILABLE:\n",
    "            return\n",
    "            \n",
    "        with self.output_widget:\n",
    "            clear_output()\n",
    "            print(\"üé¨ Starting video generation...\")\n",
    "            \n",
    "            try:\n",
    "                # Get settings\n",
    "                width, height = self.resolution_dropdown.value\n",
    "                duration = self.duration_slider.value\n",
    "                fps = self.fps_slider.value\n",
    "                num_frames = duration * fps\n",
    "                \n",
    "                # Generate video\n",
    "                frames, settings = self.pipeline.generate_video(\n",
    "                    prompt=self.prompt_input.value,\n",
    "                    negative_prompt=self.negative_prompt_input.value or None,\n",
    "                    seed=self.seed_input.value,\n",
    "                    width=width,\n",
    "                    height=height,\n",
    "                    num_frames=num_frames,\n",
    "                    fps=fps,\n",
    "                    num_inference_steps=self.steps_slider.value,\n",
    "                    guidance_scale=self.guidance_slider.value\n",
    "                )\n",
    "                \n",
    "                # Save video\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                output_path = self.output_dir / f\"video_{timestamp}.mp4\"\n",
    "                \n",
    "                success = self.pipeline.save_video(frames, str(output_path), fps=fps)\n",
    "                \n",
    "                if success:\n",
    "                    print(f\"\\n‚úÖ Video saved to: {output_path}\")\n",
    "                    self.display_video(str(output_path))\n",
    "                    \n",
    "                    # Save metadata\n",
    "                    metadata = {\n",
    "                        'prompt': self.prompt_input.value,\n",
    "                        'negative_prompt': self.negative_prompt_input.value,\n",
    "                        'settings': settings,\n",
    "                        'seed': self.seed_input.value,\n",
    "                        'timestamp': timestamp\n",
    "                    }\n",
    "                    \n",
    "                    metadata_path = output_path.with_suffix('.json')\n",
    "                    with open(metadata_path, 'w') as f:\n",
    "                        json.dump(metadata, f, indent=2, default=str)\n",
    "                        \n",
    "                else:\n",
    "                    print(\"‚ùå Failed to save video\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error: {str(e)}\")\n",
    "                \n",
    "    def generate_batch_videos(self, button=None):\n",
    "        \"\"\"Generate multiple videos in batch\"\"\"\n",
    "        if not WIDGETS_AVAILABLE:\n",
    "            return\n",
    "            \n",
    "        with self.output_widget:\n",
    "            clear_output()\n",
    "            \n",
    "            # Parse batch prompts\n",
    "            prompts = [p.strip() for p in self.batch_prompts.value.split('\\n') if p.strip()]\n",
    "            \n",
    "            if not prompts:\n",
    "                print(\"‚ùå No prompts provided for batch generation\")\n",
    "                return\n",
    "                \n",
    "            print(f\"üé¨ Starting batch generation of {len(prompts)} videos...\")\n",
    "            \n",
    "            try:\n",
    "                # Get settings\n",
    "                width, height = self.resolution_dropdown.value\n",
    "                duration = self.duration_slider.value\n",
    "                fps = self.fps_slider.value\n",
    "                num_frames = duration * fps\n",
    "                \n",
    "                # Generate videos\n",
    "                results = self.pipeline.generate_batch(\n",
    "                    prompts=prompts,\n",
    "                    width=width,\n",
    "                    height=height,\n",
    "                    num_frames=num_frames,\n",
    "                    fps=fps,\n",
    "                    num_inference_steps=self.steps_slider.value,\n",
    "                    guidance_scale=self.guidance_slider.value\n",
    "                )\n",
    "                \n",
    "                # Save successful videos\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                saved_videos = []\n",
    "                \n",
    "                for i, result in enumerate(results):\n",
    "                    if result['success']:\n",
    "                        output_path = self.output_dir / f\"batch_{timestamp}_{i+1:03d}.mp4\"\n",
    "                        success = self.pipeline.save_video(result['frames'], str(output_path), fps=fps)\n",
    "                        \n",
    "                        if success:\n",
    "                            saved_videos.append(str(output_path))\n",
    "                            print(f\"‚úÖ Video {i+1} saved: {output_path.name}\")\n",
    "                            \n",
    "                print(f\"\\nüéâ Batch generation complete! {len(saved_videos)} videos saved.\")\n",
    "                \n",
    "                # Display first video as preview\n",
    "                if saved_videos:\n",
    "                    print(\"\\nüìπ Preview of first video:\")\n",
    "                    self.display_video(saved_videos[0])\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Batch generation error: {str(e)}\")\n",
    "                \n",
    "    def display_video(self, video_path: str):\n",
    "        \"\"\"Display a video in the output\"\"\"\n",
    "        try:\n",
    "            video_widget = Video.from_file(video_path, width=640, height=360)\n",
    "            display(video_widget)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not display video: {str(e)}\")\n",
    "            print(f\"Video saved at: {video_path}\")\n",
    "            \n",
    "    def clear_output(self, button=None):\n",
    "        \"\"\"Clear the output widget\"\"\"\n",
    "        if not WIDGETS_AVAILABLE:\n",
    "            return\n",
    "            \n",
    "        with self.output_widget:\n",
    "            clear_output()\n",
    "            print(\"üóëÔ∏è Output cleared\")\n",
    "\n",
    "# Create and display the UI\n",
    "ui = VideoGeneratorUI(video_pipeline)\n",
    "ui.display_ui()\n",
    "\n",
    "print(\"\\nüé® Enhanced UI loaded! Ready to generate videos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "examples_header"
   },
   "source": [
    "## üéØ Step 6: Example Usage & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "example_usage"
   },
   "outputs": [],
   "source": [
    "# Example prompts optimized for realistic human poses\n",
    "example_prompts = [\n",
    "    \"A professional businesswoman walking confidently down a modern office hallway, natural lighting, 4K quality\",\n",
    "    \"A young man doing yoga poses in a peaceful garden, morning sunlight, cinematic composition\",\n",
    "    \"A dancer performing contemporary dance moves in an empty studio, dramatic lighting, artistic shot\",\n",
    "    \"An elderly person reading a book in a comfortable armchair by a window, warm lighting, cozy atmosphere\",\n",
    "    \"A chef preparing ingredients in a modern kitchen, professional cooking, dynamic movements\"\n",
    "]\n",
    "\n",
    "# Display example prompts\n",
    "print(\"üéØ Example Prompts for Realistic Human Poses:\")\n",
    "for i, prompt in enumerate(example_prompts, 1):\n",
    "    print(f\"\\n{i}. {prompt}\")\n",
    "\n",
    "# Quick test function\n",
    "def quick_test():\n",
    "    \"\"\"Quick test of the video generation pipeline\"\"\"\n",
    "    print(\"\\nüß™ Running quick test...\")\n",
    "    \n",
    "    try:\n",
    "        # Load pipeline\n",
    "        video_pipeline.load_pipeline()\n",
    "        \n",
    "        # Generate a short test video\n",
    "        test_frames, test_settings = video_pipeline.generate_video(\n",
    "            prompt=\"A person waving hello, friendly gesture, clear background\",\n",
    "            width=480,\n",
    "            height=320,\n",
    "            num_frames=48,  # 2 seconds at 24fps\n",
    "            fps=24,\n",
    "            num_inference_steps=25,  # Faster for testing\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        # Save test video\n",
    "        test_path = \"/content/outputs/test_video.mp4\"\n",
    "        success = video_pipeline.save_video(test_frames, test_path, fps=24)\n",
    "        \n",
    "        if success:\n",
    "            print(f\"‚úÖ Test successful! Video saved to: {test_path}\")\n",
    "            \n",
    "            # Display test video\n",
    "            from IPython.display import Video\n",
    "            display(Video(test_path, width=480, height=320))\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            print(\"‚ùå Test failed: Could not save video\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Memory status function\n",
    "def check_memory_status():\n",
    "    \"\"\"Check current memory usage\"\"\"\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "            cached = torch.cuda.memory_reserved(0) / 1024**3\n",
    "            total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "            \n",
    "            print(f\"üß† GPU Memory Status:\")\n",
    "            print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "            print(f\"  Cached: {cached:.2f} GB\")\n",
    "            print(f\"  Total: {total:.2f} GB\")\n",
    "            print(f\"  Free: {total - cached:.2f} GB\")\n",
    "            \n",
    "        # RAM status\n",
    "        import psutil\n",
    "        memory = psutil.virtual_memory()\n",
    "        print(f\"\\nüß† RAM Status:\")\n",
    "        print(f\"  Used: {memory.used / 1024**3:.2f} GB\")\n",
    "        print(f\"  Available: {memory.available / 1024**3:.2f} GB\")\n",
    "        print(f\"  Total: {memory.total / 1024**3:.2f} GB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error checking memory: {str(e)}\")\n",
    "\n",
    "# Check memory status\n",
    "check_memory_status()\n",
    "\n",
    "print(\"\\nüéØ Ready for testing! Use the UI above or run quick_test() for a quick test.\")\n",
    "print(\"\\nüí° To run a quick test, execute: quick_test()\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",\n",
  "colab": {\n",
   "gpuType": \"T4\",\n",
   "machine_shape": \"hm\",\n",
   "provenance": []\n  },\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.10.12\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 0\n}