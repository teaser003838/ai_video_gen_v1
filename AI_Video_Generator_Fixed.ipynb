{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# üé¨ AI Video Generator - Optimized for Google Colab\n",
    "\n",
    "**Features:**\n",
    "- 720p Resolution Support\n",
    "- 10-second video generation\n",
    "- 24fps output\n",
    "- Realistic human posing\n",
    "- Batch processing\n",
    "- Memory optimization\n",
    "- Progress tracking\n",
    "- Automatic environment detection\n",
    "- **FIXED:** GPUtil dependency issues resolved\n",
    "\n",
    "**Requirements:**\n",
    "- GPU Runtime (T4 or better recommended)\n",
    "- ~15GB RAM\n",
    "- ~20GB Disk Space\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_header"
   },
   "source": [
    "## üìã Step 1: Environment Detection & Setup (FIXED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "environment_detection"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import platform\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "import time\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Fixed GPUtil import with fallback\n",
    "try:\n",
    "    import GPUtil\n",
    "    GPUTIL_AVAILABLE = True\n",
    "    print(\"‚úÖ GPUtil imported successfully\")\n",
    "except ImportError:\n",
    "    GPUTIL_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è GPUtil not available, using alternative GPU detection\")\n",
    "\n",
    "class EnvironmentDetector:\n",
    "    def __init__(self):\n",
    "        self.system_info = {}\n",
    "        self.requirements_met = False\n",
    "        \n",
    "    def detect_environment(self):\n",
    "        \"\"\"Detect and validate the current environment\"\"\"\n",
    "        print(\"üîç Detecting environment...\")\n",
    "        \n",
    "        # Basic system info\n",
    "        self.system_info['platform'] = platform.system()\n",
    "        self.system_info['python_version'] = sys.version\n",
    "        self.system_info['is_colab'] = 'google.colab' in sys.modules\n",
    "        \n",
    "        # Memory info\n",
    "        memory = psutil.virtual_memory()\n",
    "        self.system_info['total_ram_gb'] = round(memory.total / (1024**3), 2)\n",
    "        self.system_info['available_ram_gb'] = round(memory.available / (1024**3), 2)\n",
    "        \n",
    "        # GPU info with fallback\n",
    "        self._detect_gpu_info()\n",
    "        \n",
    "        # Disk space\n",
    "        disk_usage = psutil.disk_usage('/')\n",
    "        self.system_info['disk_free_gb'] = round(disk_usage.free / (1024**3), 2)\n",
    "        \n",
    "        self._display_info()\n",
    "        self._check_requirements()\n",
    "        \n",
    "    def _detect_gpu_info(self):\n",
    "        \"\"\"Detect GPU information with multiple fallback methods\"\"\"\n",
    "        # Method 1: Try PyTorch first (most reliable)\n",
    "        try:\n",
    "            import torch\n",
    "            self.system_info['cuda_available'] = torch.cuda.is_available()\n",
    "            if torch.cuda.is_available():\n",
    "                self.system_info['gpu_name'] = torch.cuda.get_device_name(0)\n",
    "                self.system_info['gpu_memory_gb'] = round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 2)\n",
    "                print(\"‚úÖ GPU detected via PyTorch\")\n",
    "                return\n",
    "        except ImportError:\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è PyTorch GPU detection failed: {str(e)}\")\n",
    "            \n",
    "        # Method 2: Try GPUtil if available\n",
    "        if GPUTIL_AVAILABLE:\n",
    "            try:\n",
    "                gpus = GPUtil.getGPUs()\n",
    "                if gpus:\n",
    "                    self.system_info['cuda_available'] = True\n",
    "                    self.system_info['gpu_name'] = gpus[0].name\n",
    "                    self.system_info['gpu_memory_gb'] = round(gpus[0].memoryTotal / 1024, 2)\n",
    "                    print(\"‚úÖ GPU detected via GPUtil\")\n",
    "                    return\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è GPUtil detection failed: {str(e)}\")\n",
    "        \n",
    "        # Method 3: Try nvidia-smi command\n",
    "        try:\n",
    "            result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'], \n",
    "                                  capture_output=True, text=True, timeout=5)\n",
    "            if result.returncode == 0 and result.stdout.strip():\n",
    "                lines = result.stdout.strip().split('\\n')\n",
    "                if lines:\n",
    "                    parts = lines[0].split(', ')\n",
    "                    if len(parts) >= 2:\n",
    "                        self.system_info['cuda_available'] = True\n",
    "                        self.system_info['gpu_name'] = parts[0].strip()\n",
    "                        self.system_info['gpu_memory_gb'] = round(float(parts[1]) / 1024, 2)\n",
    "                        print(\"‚úÖ GPU detected via nvidia-smi\")\n",
    "                        return\n",
    "        except (subprocess.TimeoutExpired, FileNotFoundError, ValueError):\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è nvidia-smi detection failed: {str(e)}\")\n",
    "            \n",
    "        # No GPU detected\n",
    "        self.system_info['cuda_available'] = False\n",
    "        self.system_info['gpu_name'] = 'None'\n",
    "        self.system_info['gpu_memory_gb'] = 0\n",
    "        print(\"‚ÑπÔ∏è No GPU detected - running in CPU mode\")\n",
    "        \n",
    "    def _display_info(self):\n",
    "        \"\"\"Display system information in a nice format\"\"\"\n",
    "        info_html = f\"\"\"\n",
    "        <div style=\"background-color: #f0f2f6; padding: 15px; border-radius: 10px; margin: 10px 0;\">\n",
    "            <h3>üñ•Ô∏è System Information</h3>\n",
    "            <table style=\"width: 100%; border-collapse: collapse;\">\n",
    "                <tr><td><b>Platform:</b></td><td>{self.system_info['platform']}</td></tr>\n",
    "                <tr><td><b>Google Colab:</b></td><td>{'‚úÖ Yes' if self.system_info['is_colab'] else '‚ùå No'}</td></tr>\n",
    "                <tr><td><b>Total RAM:</b></td><td>{self.system_info['total_ram_gb']} GB</td></tr>\n",
    "                <tr><td><b>Available RAM:</b></td><td>{self.system_info['available_ram_gb']} GB</td></tr>\n",
    "                <tr><td><b>GPU:</b></td><td>{self.system_info['gpu_name']}</td></tr>\n",
    "                <tr><td><b>GPU Memory:</b></td><td>{self.system_info['gpu_memory_gb']} GB</td></tr>\n",
    "                <tr><td><b>Free Disk Space:</b></td><td>{self.system_info['disk_free_gb']} GB</td></tr>\n",
    "            </table>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(info_html))\n",
    "        \n",
    "    def _check_requirements(self):\n",
    "        \"\"\"Check if system meets requirements\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        if not self.system_info['cuda_available']:\n",
    "            issues.append(\"‚ö†Ô∏è CUDA not available - will use CPU (slower performance)\")\n",
    "        elif self.system_info['gpu_memory_gb'] < 6:\n",
    "            issues.append(\"‚ö†Ô∏è GPU memory < 6GB - may experience memory issues\")\n",
    "            \n",
    "        if self.system_info['total_ram_gb'] < 12:\n",
    "            issues.append(\"‚ö†Ô∏è RAM < 12GB - may experience memory issues\")\n",
    "            \n",
    "        if self.system_info['disk_free_gb'] < 15:\n",
    "            issues.append(\"‚ö†Ô∏è Disk space < 15GB - may not have enough space for models\")\n",
    "            \n",
    "        if issues:\n",
    "            print(\"\\n‚ö†Ô∏è System Issues Detected:\")\n",
    "            for issue in issues:\n",
    "                print(f\"  {issue}\")\n",
    "            print(\"\\nüí° Recommendation: Use Google Colab Pro with GPU runtime for best results\")\n",
    "        else:\n",
    "            print(\"\\n‚úÖ All requirements met! Ready to proceed.\")\n",
    "            self.requirements_met = True\n",
    "            \n",
    "        return len(issues) == 0\n",
    "\n",
    "# Initialize and run environment detection\n",
    "env_detector = EnvironmentDetector()\n",
    "env_detector.detect_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dependencies_header"
   },
   "source": [
    "## üì¶ Step 2: Install Dependencies (UPDATED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "class DependencyManager:\n",
    "    def __init__(self):\n",
    "        self.packages = {\n",
    "            'essential': [\n",
    "                'torch>=2.0.0',\n",
    "                'torchvision>=0.15.0',\n",
    "                'diffusers>=0.34.0',\n",
    "                'transformers>=4.53.0',\n",
    "                'accelerate>=1.8.0',\n",
    "                'xformers>=0.0.22',\n",
    "            ],\n",
    "            'video': [\n",
    "                'opencv-python-headless>=4.11.0',\n",
    "                'imageio[ffmpeg]>=2.37.0',\n",
    "                'moviepy>=2.2.0',\n",
    "                'av>=10.0.0',\n",
    "                'decord>=0.6.0'\n",
    "            ],\n",
    "            'ui': [\n",
    "                'streamlit>=1.28.0',\n",
    "                'gradio>=4.0.0',\n",
    "                'ipywidgets>=8.1.0',\n",
    "                'matplotlib>=3.10.0',\n",
    "                'pillow>=10.0.0'\n",
    "            ],\n",
    "            'utils': [\n",
    "                'huggingface-hub>=0.33.0',\n",
    "                'safetensors>=0.5.0',\n",
    "                'einops>=0.7.0',\n",
    "                'omegaconf>=2.3.0',\n",
    "                'pyngrok>=7.0.0',\n",
    "                'GPUtil>=1.4.0'  # Added GPUtil to dependencies\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "    def install_packages(self, category='all'):\n",
    "        \"\"\"Install packages with progress tracking\"\"\"\n",
    "        categories = [category] if category != 'all' else self.packages.keys()\n",
    "        \n",
    "        for cat in categories:\n",
    "            packages = self.packages[cat]\n",
    "            print(f\"\\nüì¶ Installing {cat} packages...\")\n",
    "            \n",
    "            progress_bar = tqdm(packages, desc=f\"Installing {cat}\")\n",
    "            for package in progress_bar:\n",
    "                try:\n",
    "                    progress_bar.set_postfix_str(f\"Installing {package.split('>=')[0]}\")\n",
    "                    result = subprocess.run(\n",
    "                        [sys.executable, '-m', 'pip', 'install', package, '--quiet'],\n",
    "                        capture_output=True,\n",
    "                        text=True,\n",
    "                        timeout=300\n",
    "                    )\n",
    "                    if result.returncode != 0:\n",
    "                        print(f\"\\n‚ö†Ô∏è Warning: Failed to install {package}\")\n",
    "                        print(f\"Error: {result.stderr}\")\n",
    "                except subprocess.TimeoutExpired:\n",
    "                    print(f\"\\n‚ö†Ô∏è Timeout installing {package}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"\\n‚ö†Ô∏è Error installing {package}: {str(e)}\")\n",
    "                    \n",
    "        print(\"\\n‚úÖ Dependencies installation completed!\")\n",
    "        \n",
    "    def verify_installation(self):\n",
    "        \"\"\"Verify critical packages are installed\"\"\"\n",
    "        critical_imports = {\n",
    "            'torch': 'PyTorch',\n",
    "            'diffusers': 'Diffusers',\n",
    "            'transformers': 'Transformers',\n",
    "            'cv2': 'OpenCV',\n",
    "            'imageio': 'ImageIO',\n",
    "            'streamlit': 'Streamlit'\n",
    "        }\n",
    "        \n",
    "        # Also verify GPUtil with fallback\n",
    "        print(\"\\nüîç Verifying installations...\")\n",
    "        \n",
    "        # Check GPUtil specifically\n",
    "        try:\n",
    "            import GPUtil\n",
    "            print(\"‚úÖ GPUtil - OK\")\n",
    "        except ImportError:\n",
    "            print(\"‚ö†Ô∏è GPUtil - NOT FOUND (will use alternatives)\")\n",
    "            \n",
    "        for module, name in critical_imports.items():\n",
    "            try:\n",
    "                __import__(module)\n",
    "                print(f\"‚úÖ {name} - OK\")\n",
    "            except ImportError:\n",
    "                print(f\"‚ùå {name} - FAILED\")\n",
    "                \n",
    "        # Check CUDA availability\n",
    "        try:\n",
    "            import torch\n",
    "            if torch.cuda.is_available():\n",
    "                print(f\"‚úÖ CUDA - OK (Device: {torch.cuda.get_device_name(0)})\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è CUDA - Not available (will use CPU)\")\n",
    "        except:\n",
    "            print(\"‚ùå CUDA - Error checking\")\n",
    "\n",
    "# Install dependencies\n",
    "dep_manager = DependencyManager()\n",
    "dep_manager.install_packages()\n",
    "dep_manager.verify_installation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_header"
   },
   "source": [
    "## üß™ Step 3: Test Fixed Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_environment"
   },
   "outputs": [],
   "source": [
    "def test_fixed_environment():\n",
    "    \"\"\"Test that all the fixes work properly\"\"\"\n",
    "    print(\"üß™ Testing Fixed Environment\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Test 1: GPUtil import\n",
    "    print(\"\\n1. Testing GPUtil import...\")\n",
    "    try:\n",
    "        import GPUtil\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        print(f\"   ‚úÖ GPUtil works! Found {len(gpus)} GPU(s)\")\n",
    "        if gpus:\n",
    "            for i, gpu in enumerate(gpus):\n",
    "                print(f\"      GPU {i}: {gpu.name} ({gpu.memoryTotal}MB)\")\n",
    "    except ImportError:\n",
    "        print(\"   ‚ö†Ô∏è GPUtil not available, testing alternatives...\")\n",
    "        \n",
    "    # Test 2: PyTorch GPU detection\n",
    "    print(\"\\n2. Testing PyTorch GPU detection...\")\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"   ‚úÖ PyTorch CUDA available: {torch.cuda.get_device_name(0)}\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è PyTorch CUDA not available - will use CPU\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå PyTorch test failed: {str(e)}\")\n",
    "    \n",
    "    # Test 3: System info\n",
    "    print(\"\\n3. Testing system info...\")\n",
    "    try:\n",
    "        import psutil\n",
    "        memory = psutil.virtual_memory()\n",
    "        print(f\"   ‚úÖ RAM: {memory.total / 1024**3:.1f}GB total\")\n",
    "        \n",
    "        disk = psutil.disk_usage('/')\n",
    "        print(f\"   ‚úÖ Disk: {disk.free / 1024**3:.1f}GB free\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå System info failed: {str(e)}\")\n",
    "    \n",
    "    # Test 4: Required packages\n",
    "    print(\"\\n4. Testing required packages...\")\n",
    "    required_packages = ['torch', 'transformers', 'diffusers', 'opencv-python-headless', 'imageio']\n",
    "    \n",
    "    for package in required_packages:\n",
    "        try:\n",
    "            if package == 'opencv-python-headless':\n",
    "                import cv2\n",
    "                print(f\"   ‚úÖ {package} (cv2) - OK\")\n",
    "            else:\n",
    "                __import__(package)\n",
    "                print(f\"   ‚úÖ {package} - OK\")\n",
    "        except ImportError:\n",
    "            print(f\"   ‚ùå {package} - MISSING\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Environment test completed!\")\n",
    "    print(\"\\nüí° You can now proceed with the rest of the notebook.\")\n",
    "    print(\"   If you encounter any issues, check the error messages above.\")\n",
    "\n",
    "# Run the test\n",
    "test_fixed_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "continuation_header"
   },
   "source": [
    "## üîÑ Step 4: Continue with Original Notebook\n",
    "\n",
    "The GPUtil issue has been fixed! You can now continue with the rest of your original notebook.\n",
    "\n",
    "**What was fixed:**\n",
    "1. ‚úÖ GPUtil module is now properly installed\n",
    "2. ‚úÖ Alternative GPU detection methods added as fallbacks\n",
    "3. ‚úÖ Error handling improved for different environments\n",
    "4. ‚úÖ Dependencies updated and verified\n",
    "\n",
    "**Next steps:**\n",
    "- Continue with model downloads (Step 3 from original notebook)\n",
    "- Set up the video generation pipeline (Step 4 from original notebook)\n",
    "- Use the enhanced UI (Step 5 from original notebook)\n",
    "\n",
    "The rest of your original notebook should now work without the GPUtil import errors!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}